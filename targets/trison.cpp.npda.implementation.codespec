<|if(is_defined(generate_debug_spew_code))
template <typename T>
std::ostream &operator << (std::ostream &out, std::set<T> const &s)
{
    out << "{ ";
    for (typename std::set<T>::const_iterator it = s.begin(), it_end = s.end(); it != it_end; ++it)
        out << *it << ", ";
    out << '}';
    return out;
}

template <typename T>
std::ostream &operator << (std::ostream &out, std::vector<T> const &s)
{
    out << "[ ";
    for (typename std::vector<T>::const_iterator it = s.begin(), it_end = s.end(); it != it_end; ++it)
        out << *it << ", ";
    out << ']';
    return out;
}

<|end_if
std::uint32_t <{class_name}::NonterminalStartStateIndex_ (<{class_name}::Nonterminal::Name nonterminal)
{
    switch (nonterminal)
    {
<|      for_each(key, _npda_nonterminal_start_state_index)
        case Nonterminal::<{key}: return <{_npda_nonterminal_start_state_index[key]};
<|      end_for_each
        default: assert(false && "invalid nonterminal"); return 0;
    }
}

bool <{class_name}::HasEncounteredErrorState () const
{
    return (m_realized_state_ == NULL) ? false : m_realized_state_->HasEncounteredErrorState();
}

std::int64_t <{class_name}::MaxAllowableLookaheadCount () const
{
    return m_max_allowable_lookahead_count;
}

std::size_t <{class_name}::MaxRealizedLookaheadCount () const
{
    return (m_realized_state_ == NULL) ? 0 : m_realized_state_->MaxRealizedLookaheadCount();
}

std::int64_t <{class_name}::MaxAllowableLookaheadQueueSize () const
{
    return m_max_allowable_lookahead_queue_size;
}

std::size_t <{class_name}::MaxRealizedLookaheadQueueSize () const
{
    return (m_realized_state_ == NULL) ? 0 : m_realized_state_->MaxRealizedLookaheadQueueSize();
}

std::int64_t <{class_name}::MaxAllowableParseTreeDepth () const
{
    return m_max_allowable_parse_tree_depth;
}

std::uint32_t <{class_name}::MaxRealizedParseTreeDepth () const
{
    return (m_hypothetical_state_ == NULL) ? 0 : m_hypothetical_state_->m_max_realized_parse_tree_depth;
}

void <{class_name}::SetMaxAllowableLookaheadCount (std::int64_t max_allowable_lookahead_count)
{
    m_max_allowable_lookahead_count = max_allowable_lookahead_count;
}

void <{class_name}::SetMaxAllowableLookaheadQueueSize (std::int64_t max_allowable_lookahead_queue_size)
{
    m_max_allowable_lookahead_queue_size = max_allowable_lookahead_queue_size;
}

void <{class_name}::SetMaxAllowableParseTreeDepth (std::int64_t max_allowable_parse_tree_depth)
{
    m_max_allowable_parse_tree_depth = max_allowable_parse_tree_depth;
}

<{class_name}::ParserReturnCode <{class_name}::Parse_ (<{token_data_type} *return_token, Nonterminal::Name nonterminal_to_parse)
{
    assert(return_token != NULL && "the return-token pointer must be non-NULL");

<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_START_END_PARSE, *DebugSpewStream() << <{debug_spew_prefix} << "Starting parse\n")

<|  end_if
    ParserReturnCode parser_return_code_ = PRC_INTERNAL_ERROR;
    *return_token = <{token_data_default};

<|  if(is_defined(enable_scan_actions_exceptions) || is_defined(enable_reduction_rule_exceptions))
    // this is the try {} block generated by specifying the
    // %target.cpp.enable_scan_actions_exceptions or
    // %target.cpp.enable_reduction_rule_exceptions directives in the
    // primary source, to allow necessary cleanup if the scan actions
    // or a reduction rule code block throws an exception.
    try {

<|  end_if

    std::uint32_t start_state_index = NonterminalStartStateIndex_(nonterminal_to_parse);

    if (m_realized_state_ != NULL) // This happens when parsing again, not from scratch.
    {
        assert(m_hypothetical_state_ == NULL);
        // Note that this resets the error state.
        m_realized_state_->Reinitialize(start_state_index);
        // Delete this entirely to be initialized anew, since it has no state that
        // carries over between parses.
        delete m_hypothetical_state_;
        m_hypothetical_state_ = NULL;
    }
    else // This happens when parsing for the first time.
        m_realized_state_ = new RealizedState_(start_state_index);

    m_hypothetical_state_ = new HypotheticalState_(start_state_index);

<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_STACK_AND_LOOKAHEADS,
        *DebugSpewStream() << <{debug_spew_prefix} << "<stack> . <lookaheads>: ";
        m_realized_state_->PrintStackAndLookaheads(*DebugSpewStream());
        *DebugSpewStream() << '\n';
    )

<|  end_if
    bool should_return = false;
<|  if(is_defined(generate_debug_spew_code))
    std::size_t iteration_index = 0;
<|  end_if
    while (!should_return)
    {
<|      if(is_defined(generate_debug_spew_code))
        TRISON_CPP_DEBUG_CODE_(
            DSF_ITERATION_COUNT,
            *DebugSpewStream() << <{debug_spew_prefix} << "\n";
            *DebugSpewStream() << <{debug_spew_prefix} << "---------- ITERATION " << iteration_index << " --------------\n";
            PrintParserStatus_(*DebugSpewStream());
            *DebugSpewStream() << <{debug_spew_prefix} << '\n';
        )

<|      end_if
        if (m_realized_state_->HasExceededMaxAllowableLookaheadCount(m_max_allowable_lookahead_count))
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << <{debug_spew_prefix} << "Max realized lookahead count (" << m_realized_state_->MaxRealizedLookaheadCount() << ") has exceeded max allowable lookahead token count (" << m_max_allowable_lookahead_count << "); modify this limit using the default_max_allowable_lookahead_count directive (see trison.cpp.targetspec), or using the SetMaxAllowableLookaheadCount method.  Returning with error.\n")
<|          end_if
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_COUNT;
            break;
        }

        if (m_realized_state_->HasExceededMaxAllowableLookaheadQueueSize(m_max_allowable_lookahead_queue_size))
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << <{debug_spew_prefix} << "Max realized lookahead queue size (" << m_realized_state_->MaxRealizedLookaheadQueueSize() << ") has exceeded max allowable lookahead queue size (" << m_max_allowable_lookahead_queue_size << "); modify this limit using the default_max_allowable_lookahead_queue_size directive (see trison.cpp.targetspec), or using the SetMaxAllowableLookaheadQueueSize method.  Returning with error.\n")
<|          end_if
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_QUEUE_SIZE;
            break;
        }

        if (m_hypothetical_state_->HasExceededMaxAllowableParseTreeDepth(m_max_allowable_parse_tree_depth))
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << <{debug_spew_prefix} << "Parse tree depth (" << m_hypothetical_state_->ParseTreeDepth() << ") has exceeded max allowable parse tree depth (" << m_max_allowable_parse_tree_depth << "); modify this limit using the default_max_allowable_parse_tree_depth directive (see trison.cpp.targetspec), or using the SetMaxAllowableParseTreeDepth method.  Returning with error.\n")
<|          end_if
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_PARSE_TREE_DEPTH;
            break;
        }

        if (m_hypothetical_state_->m_root->HasTrunkChild())
            ExecuteAndRemoveTrunkActions_(should_return, parser_return_code_, return_token);
        else
            ContinueNPDAParse_(should_return);
<|      if(is_defined(generate_debug_spew_code))

        TRISON_CPP_DEBUG_CODE_(DSF_ITERATION_COUNT, *DebugSpewStream() << <{debug_spew_prefix} << '\n')
        ++iteration_index;
<|      end_if
    }

<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(
        DSF_ITERATION_COUNT,
        *DebugSpewStream() << <{debug_spew_prefix} << "\n";
        *DebugSpewStream() << <{debug_spew_prefix} << "---------- RETURNING --------------\n";
        PrintParserStatus_(*DebugSpewStream());
        *DebugSpewStream() << <{debug_spew_prefix} << '\n';
    )

<|  end_if
<|  if(is_defined(enable_scan_actions_exceptions) || is_defined(enable_reduction_rule_exceptions))
    // this is the catch {} block generated by specifying the
    // %target.cpp.enable_scan_actions_exceptions or
    // %target.cpp.enable_reduction_rule_exceptions directives in the
    // primary source, to allow necessary cleanup if the scan actions
    // or a reduction rule code block throws an exception.
    } catch (...) {
        // Clear the stack, because we won't need it for the next parse.  We don't clear the
        // lookahead queue here because we might want to parse multiple times from the same
        // input, and the lookahead queue could have the next few tokens in it.
        ClearStack_();
        assert(m_realized_state_ != NULL);
        assert(m_hypothetical_state_ == NULL);
        // Rethrow the (unknown) exception.
        throw;
    }

<|  end_if
<|  if(is_defined(generate_debug_spew_code))
    assert(std::size_t(parser_return_code_) < ms_parser_return_code_string_count_ && "this should never happen");
    TRISON_CPP_DEBUG_CODE_(
        DSF_START_END_PARSE,
        *DebugSpewStream() << <{debug_spew_prefix} << "Parse() is returning " << ms_parser_return_code_string_table_[parser_return_code_] << '\n';
    )

<|  end_if
    return parser_return_code_;
}

void <{class_name}::ExecuteAndRemoveTrunkActions_ (bool &should_return, ParserReturnCode &parser_return_code_, <{token_data_type} *&return_token)
{
<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << "Parse stack tree has trunk; executing trunk actions.\n")
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << '\n')

<|  end_if
    if (m_hypothetical_state_->m_root->HasTrunkChild())
    {
        // The trunk_child is popped and then will die by the end of this function.
        // Using std::unique_ptr for exception safety -- if an exception is thrown within
        // this function, then trunk_child still needs to be deleted.
        std::unique_ptr<ParseTreeNode_> trunk_child(m_hypothetical_state_->m_root->PopTrunkChild());
        assert(trunk_child->m_parent_node == NULL);
        assert(trunk_child->m_child_nodes.empty());

        bool destroy_and_recreate_parse_tree = false;

        switch (trunk_child->m_spec.m_type)
        {
            case ParseTreeNode_::RETURN: {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action RETURN.\n")
<|              end_if
                assert(m_realized_state_->TokenStack().size() == 2);
                parser_return_code_ = PRC_SUCCESS;
                // This doesn't change the structure of the stack but does take ownership of the top stack token.
                // This must be done so that the return token isn't destroyed with the parser.
                m_realized_state_->StealTokenStackTop(return_token);
                should_return = true;
                break;
            }
            case ParseTreeNode_::REDUCE: {
                // Execute the appropriate rule on the top tokens in the stack
                std::uint32_t const &rule_index = trunk_child->m_spec.m_single_data;
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action REDUCE rule " << rule_index << "; " << Grammar_::ms_rule_table_[rule_index].m_description << '\n')
<|              end_if
                Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[rule_index];
                Token::Data reduced_nonterminal_token_data = ExecuteReductionRule_(rule_index, m_realized_state_->TokenStack());
                m_realized_state_->ExecuteActionReduce(rule, reduced_nonterminal_token_data, m_hypothetical_state_->m_hps_queue);
                // This is done essentially so that m_realized_lookahead_cursor can be reset.
                destroy_and_recreate_parse_tree = true;
                break;
            }
            case ParseTreeNode_::SHIFT: {
<|              if(is_defined(generate_debug_spew_code))
                std::uint32_t const &shifted_token_id = trunk_child->m_spec.m_single_data;
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action SHIFT " << Token(shifted_token_id) << '\n')
<|              end_if
                m_realized_state_->ExecuteActionShift(trunk_child->m_child_branch_vector, m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::INSERT_LOOKAHEAD_ERROR: {
                // INSERT_LOOKAHEAD_ERROR -- this should have access to the lookahead that
                // caused the error to be generated, and it should return a token that will
                // be used as the %error token.
                //
                // Start:  <realized-stack-tokens> . <lookahead>
                //                                 ^~~~~~~~~~^
                //                                 input to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <lookahead>
                //                                   ^~~~~~~^
                //                                   output from handler code

<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action INSERT_LOOKAHEAD_ERROR, and setting has-encountered-error-state flag.\n")
<|              end_if
                Token lookahead = Lookahead_(0);
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "HIPPO 2 lookahead retrieved from Lookahead_(0) for INSERT_LOOKAHEAD_ERROR action is " << ms_token_name_table_[lookahead.m_id] << '\n')
<|              end_if
                Token resulting_error_token(Terminal::ERROR_, InsertLookaheadErrorActions_(lookahead));
                m_realized_state_->PushFrontLookahead(resulting_error_token, m_hypothetical_state_->m_hps_queue);
                m_realized_state_->SetHasEncounteredErrorState();
                //m_realized_state_->ExecuteActionInsertLookaheadError(m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::DISCARD_LOOKAHEAD: {
                // DISCARD_LOOKAHEAD -- this can only happen if the top of the realized stack
                // is %error; it should have access to the %error token and the lookahead
                // token, and it should return a token that will be used as the resulting
                // %error token (e.g. combining the file locations of the two input tokens).
                //
                // Start:  <realized-stack-tokens> <%error> . <lookahead0> <rest-of-lookaheads>
                //                                 ^~~~~~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> <%error> . <rest-of-lookaheads>
                //                                 ^~~~~~~^
                //                                 output from handler code (old stack top is replaced)

<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action DISCARD_LOOKAHEAD.\n")
<|              end_if
                Token stack_top_error_token = m_realized_state_->TokenStack().back();
                assert(stack_top_error_token.m_id == Terminal::ERROR_);
                Token lookahead(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue));
                Token resulting_error_token = Token(Terminal::ERROR_, DiscardLookaheadActions_(stack_top_error_token, lookahead));
                m_realized_state_->ReplaceTokenStackTopWith(resulting_error_token);
                //m_realized_state_->ExecuteActionDiscardLookahead(m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::POP_STACK: {
                // POP_STACK 1 -- this can only happen when the lookahead is %error (and in
                // this case, the top of the realized stack is not %error); it should have
                // access to the token about to be popped and the lookahead %error token, and
                // it should return a token that will be used as the resulting %error token
                // (e.g. combining the file locations of the two input tokens).
                //
                // Start:  <realized-stack-tokens> <token0> . <%error> <rest-of-lookaheads>
                //                                 ^~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <rest-of-lookaheads>
                //                                 ^~~~~~~^
                //                                 output from handler code
                //
                // POP_STACK 2 -- this can only happen when the lookahead is %end; it should
                // have access to the 2 tokens about to be popped and the lookahead %end token,
                // and it should return a token that will be used as the resulting %error token
                // (e.g. combining the file locations of the three input tokens).
                //
                // Start:  <realized-stack-tokens> <token1> <token0> . <%end>
                //                                 ^~~~~~~~~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <%end>
                //                                 ^~~~~~~^
                //                                 output from handler code
                //
                // NOTE: The semantics for POP_STACK 1 and POP_STACK 2 are different; the handler
                // code is expected to consume (e.g. delete, aggregate, etc) all inputs for
                // POP_STACK 1, and is expected to only consume the popped stack tokens for
                // POP_STACK 2 (and only read from the lookahead).

                std::uint32_t const &pop_count = trunk_child->m_spec.m_single_data;
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Executing trunk action POP_STACK " << pop_count << ".\n")
<|              end_if
                assert(pop_count == 1 || pop_count == 2);

                // This one is tricky to implement within RealizedState_ alone, mainly because
                // of the ThrowAwayToken_ call.
                if (m_realized_state_->TokenStack().size() > pop_count)
                {
                    std::vector<Token> popped_tokens(pop_count, Token(Nonterminal::none_));
                    for (std::uint32_t i = 0; i < pop_count; ++i)
                    {
                        // TODO: Could print the m_realized_state_ m_branch_vector_stack element being popped.
                        popped_tokens[pop_count-1-i] = m_realized_state_->PopStack();
                        //ThrowAwayToken_(m_realized_state_->PopStack());
                    }
                    assert(popped_tokens.size() == pop_count);
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')
<|                  end_if

                    Token lookahead(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue));
                    //Token lookahead(Lookahead_(0));
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "lookahead for POP_STACK action is " << ms_token_name_table_[lookahead.m_id] << '\n')
<|                  end_if
                    Token resulting_error_token(Terminal::ERROR_);
                    if (pop_count == 1)
                    {
                        assert(lookahead.m_id == Terminal::ERROR_);
                        resulting_error_token.m_data = PopStack1Actions_(popped_tokens, lookahead);
                        //Token popped_lookahead_token = m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue);
                        //assert(popped_lookahead_token.m_id == lookahead.m_id);
                    }
                    else
                    {
                        assert(lookahead.m_id == Terminal::END_);
                        resulting_error_token.m_data = PopStack2Actions_(popped_tokens, lookahead);
                    }
                    m_realized_state_->PushFrontLookahead(resulting_error_token, m_hypothetical_state_->m_hps_queue);
                }
                else
                {
                    // We're popping more than the whole stack, which is an error
                    parser_return_code_ = PRC_UNHANDLED_PARSE_ERROR;
                    should_return = true;
                }

                // Because POP_STACK involves popping the stack, the parse tree should be destroyed and
                // recreated (from the branches in the top of the realized state stack).  This is somewhat
                // draconian and non-optimal, but simple and effective.
                destroy_and_recreate_parse_tree = true;
                // TODO: Because HPS branches are blocked right after POP_STACK, maybe don't bother adding any
                // additional children below POP_STACK nodes (i.e. one HPS child of POP_STACK is sufficient to
                // keep it alive probably).  This would reduce the number of memory operations.
                break;
            }

            default:
                assert(false && "this should not happen");
                break;
        }
<|      if(is_defined(generate_debug_spew_code))

        TRISON_CPP_DEBUG_CODE_(DSF_STACK_AND_LOOKAHEADS,
            *DebugSpewStream() << <{debug_spew_prefix} << "<stack> . <lookaheads>: ";
            m_realized_state_->PrintStackAndLookaheads(*DebugSpewStream());
            *DebugSpewStream() << '\n';
        )
<|      end_if

        if (destroy_and_recreate_parse_tree)
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << "    Destroying and recreating parse tree based on top of branch stack of of realized state.\n")
<|          end_if
            m_hypothetical_state_->DestroyParseTree();
            CreateParseTreeFromRealizedState_();
        }
    }
}

void <{class_name}::ContinueNPDAParse_ (bool &should_return)
{
    // If there are no non-blocked hps-es, then the parse should stop.  If any non-blocked hps-es
    // are processed, then this flag will be set to false.
    should_return = true;

<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << "Parse stack tree does not have trunk; continuing parse.\n")

<|  end_if
    // If there's a SHIFT/REDUCE conflict, then see if it can be resolved first.
    {
        ParseTreeNode_ *shift  = NULL;
        ParseTreeNode_ *reduce = NULL;
        // TODO: Move this handling into its own function
        // NOTE: This only works at the root.  If that were to change, then various things
        // would need to scan over only the HPSes that are contained within the relevant subtree.
        bool has_shift_reduce_conflict = m_hypothetical_state_->m_root->HasShiftReduceConflict(shift, reduce);
        bool has_shift_reduce_conflict_and_should_resolve = false;
        if (has_shift_reduce_conflict)
        {
            // Should not do anything unless the shift and reduce branches have the same
            // m_realized_lookahead_cursor (e.g. a REDUCE action will start out with
            // m_realized_lookahead_cursor == 0, while a SHIFT action will start out with
            // m_realized_lookahead_cursor == 1, but the REDUCE action branch needs to be
            // allowed to catch up before having any chance at the SHIFT/REDUCE conflict
            // being resolvable).
            if (m_hypothetical_state_->MinAndMaxRealizedLookaheadCursorsAreEqual())
                has_shift_reduce_conflict_and_should_resolve = true;
<|          if(is_defined(generate_debug_spew_code))
            else
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "    SHIFT/REDUCE conflict encountered, but the min and max realized lookahead cursors for all HPSes are not equal, so it's not ready for the conflict to be resolved.\n")
            }
<|          end_if
        }

        if (has_shift_reduce_conflict_and_should_resolve)
        {
            assert(shift != NULL);
            assert(reduce != NULL);
            ParseTreeNode_::PrecedenceLevelRange shift_precedence_level_range = shift->ComputePrecedenceLevelRange(1);
            ParseTreeNode_::PrecedenceLevelRange reduce_precedence_level_range = reduce->ComputePrecedenceLevelRange(1);
            assert(reduce_precedence_level_range.first == reduce_precedence_level_range.second);

<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "    SHIFT/REDUCE conflict encountered. REDUCE precedence level range: [" << Grammar_::ms_precedence_table_[reduce_precedence_level_range.first].m_name << ", " << Grammar_::ms_precedence_table_[reduce_precedence_level_range.second].m_name << "], SHIFT precedence level range: [" << Grammar_::ms_precedence_table_[shift_precedence_level_range.first].m_name << ", " << Grammar_::ms_precedence_table_[shift_precedence_level_range.second].m_name << "]\n")

<|          end_if
            // 6 possibilities (the higher lines indicate higher precedence level.  same line
            // indicates equality).  there is always exactly one reduce hps, and at least
            // one shift hps.
            //
            // note that if a shift and a reduce have the same precedence level, then they also
            // have the same associativity.
            //
            // 1.     shift        2.     shift        3.
            //        shift               shift
            // reduce              reduce shift        reduce shift
            //
            // 4.                  5.                  6.
            //                                                shift
            // reduce shift        reduce              reduce shift
            //        shift               shift               shift
            //        shift               shift
            //
            // cases 1 and 5 can be trivially resolved -- by pruning the reduce
            // and by pruning the shift respectively.
            //
            // case 2 can only be resolved if the associativity of the reduction rule
            // is RIGHT, in which case the reduce is pruned.  otherwise no resolution
            // can be reached at this point.
            //
            // case 3 may be trivially resolved via rule associativity (LEFT causes the
            // shift to be pruned, RIGHT causes the reduce to be pruned, and NONASSOC
            // should cause an error).
            //
            // case 4 can only be resolved if the associativity of the reduction rule
            // is LEFT, in which case the shift is pruned.  otherwise no resolution
            // can be reached at this point.
            //
            // case 6 can not be resolved at this point.

            bool conflict_resolved = false;

            // Case 1
            if (reduce_precedence_level_range.second < shift_precedence_level_range.first)
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 1; REDUCE < SHIFT; pruning REDUCE and continuing.\n")
<|              end_if
                // TODO: Use std::unique_ptr and pass in via move so that the `reduce = NULL` is unnecessary.
                m_hypothetical_state_->DeleteBranch(reduce);
                reduce = NULL;
                conflict_resolved = true;
            }
            // Case 2
            else if (reduce_precedence_level_range.first == shift_precedence_level_range.first &&
                     shift_precedence_level_range.first < shift_precedence_level_range.second)
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 2; REDUCE <= SHIFT;\n")
<|              end_if
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
                if (reduction_rule_precedence.m_associativity == Grammar_::ASSOC_RIGHT)
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Pruning REDUCE (because it is right-associative) and continuing.\n")
<|                  end_if
                    m_hypothetical_state_->DeleteBranch(reduce);
                    reduce = NULL;
                    conflict_resolved = true;
                }
                else
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Can't resolve conflict at this time.\n")
<|                  else
                    // Can't resolve the conflict at this time.
<|                  end_if
                }
            }
            // Case 3
            else if (reduce_precedence_level_range.second == shift_precedence_level_range.first &&
                     shift_precedence_level_range.first == shift_precedence_level_range.second)
            {
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 3; REDUCE == SHIFT; rule " << reduce->m_spec.m_single_data << " associativity: " <<
 Grammar_::ms_associativity_string_table_[reduction_rule_precedence.m_associativity] << '\n')
<|              end_if
                switch (reduction_rule_precedence.m_associativity)
                {
                    case Grammar_::ASSOC_LEFT:
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Pruning SHIFT (because REDUCE is left-associative) and continuing.\n")
<|                      end_if
                        m_hypothetical_state_->DeleteBranch(shift);
                        shift = NULL;
                        conflict_resolved = true;
                        break;

                    case Grammar_::ASSOC_NONASSOC:
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Composition of nonassoc rules with the same precedence is an error.  Pruning both SHIFT and REDUCE.  Recreating parse tree under INSERT_LOOKAHEAD_ERROR action.\n")
<|                      end_if
                        // Neither SHIFT nor REDUCE should survive.  Instead, create an INSERT_LOOKAHEAD_ERROR
                        // action to initiate error panic.  This works only because the shift and reduce nodes
                        // are children of the parse tree root.
                        assert(shift->m_parent_node == m_hypothetical_state_->m_root);
                        assert(reduce->m_parent_node == m_hypothetical_state_->m_root);

                        // Lookahead_(0) is the token that would be SHIFT'ed.
                        RunNonassocErrorActions_(Lookahead_(0));

                        m_hypothetical_state_->DeleteBranch(shift);
                        m_hypothetical_state_->DeleteBranch(reduce);
                        // Just verify that the HPS queue has been totally nullified by the above actions.
                        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                        {
                            assert(*hps_it == NULL);
                        }
                        m_hypothetical_state_->m_hps_queue.clear();
                        assert(m_hypothetical_state_->m_new_hps_queue.empty());
                        assert(m_hypothetical_state_->m_root->m_child_nodes.empty());

                        // Create fresh HPSes at the root from the realized state.
                        CreateParseTreeFromRealizedState_();
                        // TODO: This operation could be optimized due to the fact that each HPS will
                        // take exactly one action; INSERT_LOOKAHEAD_ERROR.  But for now, just do the
                        // easy thing.
                        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                        {
                            ParseTreeNode_ *hps = *hps_it;
                            assert(hps != NULL);
                            ParseTreeNode_ *new_hps = TakeHypotheticalActionOnHPS_(*hps, ParseTreeNode_::INSERT_LOOKAHEAD_ERROR, ParseTreeNode_::UNUSED_DATA);
                            m_hypothetical_state_->m_new_hps_queue.push_back(new_hps);
                            // Note that DeleteBranch only nullifies elements in m_hps_queue, it doesn't
                            // alter the container itself.
                            m_hypothetical_state_->DeleteBranch(hps);
                        }
                        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                        {
                            assert(*hps_it == NULL);
                        }
                        m_hypothetical_state_->m_hps_queue.clear();

                        // Now that all the INSERT_LOOKAHEAD_ERROR HPSes have been created and put into
                        // m_new_hps_queue, the existing HPSes have been deleted, and the processing later
                        // in this function (see `if (conflict_resolved)` block) is expecting the HPSes to
                        // be in m_hps_queue, swap the queues.
                        assert(m_hypothetical_state_->m_hps_queue.empty());
                        assert(!m_hypothetical_state_->m_new_hps_queue.empty());
                        std::swap(m_hypothetical_state_->m_hps_queue, m_hypothetical_state_->m_new_hps_queue);

                        // Mark the conflict as resolved.
                        conflict_resolved = true;
                        break;

                    case Grammar_::ASSOC_RIGHT:
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Pruning REDUCE (because it is right-associative) and continuing.\n")
<|                      end_if
                        m_hypothetical_state_->DeleteBranch(reduce);
                        reduce = NULL;
                        conflict_resolved = true;
                        break;

                    default:
                        assert(false && "this should never happen");
                        break;
                }
            }
            // Case 4
            else if (reduce_precedence_level_range.second == shift_precedence_level_range.second &&
                     shift_precedence_level_range.first < shift_precedence_level_range.second)
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 4; REDUCE >= SHIFT;\n")
<|              end_if
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
                if (reduction_rule_precedence.m_associativity == Grammar_::ASSOC_LEFT)
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Pruning SHIFT (because REDUCE is left-associative) and continuing.\n")
<|                  end_if
                    m_hypothetical_state_->DeleteBranch(shift);
                    shift = NULL;
                    conflict_resolved = true;
                }
                else
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Can't resolve conflict at this time.\n")
<|                  else
                    // Can't resolve the conflict at this time.
<|                  end_if
                }
            }
            // Case 5
            else if (reduce_precedence_level_range.first > shift_precedence_level_range.second)
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 5; REDUCE > SHIFT; pruning SHIFT and continuing.\n")
<|              end_if
                m_hypothetical_state_->DeleteBranch(shift);
                shift = NULL;
                conflict_resolved = true;
            }
            // Case 6
            else {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "        Case 6; ambiguous SHIFT/REDUCE precedence comparison; can't resolve conflict at this time.\n")
<|              else
                // Ambiguous SHIFT/REDUCE precedence comparison; can't resolve the conflict at this time.
<|              end_if
                assert(reduce_precedence_level_range.first > shift_precedence_level_range.first);
                assert(reduce_precedence_level_range.second < shift_precedence_level_range.second);
            }

            if (conflict_resolved)
            {
                should_return = false;

                assert(m_hypothetical_state_->m_new_hps_queue.empty());
                // Take new hps-es and clear old ones.
                for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                {
                    ParseTreeNode_ *hps = *hps_it;
                    if (hps != NULL)
                        m_hypothetical_state_->m_new_hps_queue.push_back(hps);
                }
                m_hypothetical_state_->m_hps_queue.clear();
                std::swap(m_hypothetical_state_->m_hps_queue, m_hypothetical_state_->m_new_hps_queue);
                assert(m_hypothetical_state_->m_new_hps_queue.empty());
                // TODO: Break this large function up into smaller logical units
                return;
            }
        }
    }

    // Compute the minimum of all hps-es' m_realized_lookahead_cursor values, in order
    // to determine which ones have processed the lowest number of lookaheads.  This is
    // done so that one hps doesn't get way ahead of the others.
    std::uint32_t min_realized_lookahead_cursor;
    m_hypothetical_state_->ComputeMinAndMaxRealizedLookaheadCursors(&min_realized_lookahead_cursor, NULL);

    // Process transitions in order of their SortedTypeIndex.  Only process HPSes that are at min_realized_lookahead_cursor.
    assert(m_hypothetical_state_->m_new_hps_queue.empty()); // This is the starting condition
    for (std::uint32_t current_sorted_type_index = 0; current_sorted_type_index <= 3; ++current_sorted_type_index)
    {
<|      if(is_defined(generate_debug_spew_code))
        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << <{debug_spew_prefix} << "    Processing transitions having SortedTypeIndex equal to " << current_sorted_type_index << " and m_realized_lookahead_cursor equal to " << min_realized_lookahead_cursor << ".\n")

<|      end_if
        if (!m_hypothetical_state_->m_new_hps_queue.empty())
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << <{debug_spew_prefix} << "        Early-out based on sorted type index.\n")
<|          end_if
            break;
        }

        // Process non-blocked hps-es.
        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
        {
            // Skip nullified HPS nodes.
            if (*hps_it == NULL)
                continue;

            ParseTreeNode_ &hps = **hps_it;

            assert(hps.m_spec.m_type == ParseTreeNode_::HPS);
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(
                DSF_TRANSITION_PROCESSING,
                *DebugSpewStream() << <{debug_spew_prefix} << "        Processing ";
                hps.Print(*DebugSpewStream(), this, DebugSpewPrefix(), 0, true);
            )

<|          end_if
            // If a hps is blocked, then save it for the next parse iteration but don't do anything with it.
            if (hps.IsBlockedHPS())
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << <{debug_spew_prefix} << "            Hypothetical Parser State is blocked; preserving for next iteration.\n")
<|              end_if
                m_hypothetical_state_->m_new_hps_queue.push_back(&hps);
                *hps_it = NULL;
                continue;
            }

            // If a hps' m_realized_lookahead_cursor is greater than min_realized_lookahead_cursor, then
            // save it for the next parse iteration but don't do anything with it.
            if (hps.m_realized_lookahead_cursor > min_realized_lookahead_cursor)
            {
<|              if(is_defined(generate_debug_spew_code))
                TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << <{debug_spew_prefix} << "            Hypothetical Parser State isn't at min_realized_lookahead_cursor (which is " << min_realized_lookahead_cursor << "); preserving for next iteration.\n")
<|              end_if
                m_hypothetical_state_->m_new_hps_queue.push_back(&hps);
                *hps_it = NULL;
                continue;
            }

            // This hps isn't blocked, so indicate that the parse should continue.
            should_return = false;

            std::uint32_t hps_state_index = hps.m_hypothetical_head.StatePtr()->Data();

            // Retrieve all transitions whose SortedTypeIndex is current_sorted_type_index.
            Npda_::TransitionVector_ const &non_epsilon_transitions = Npda_::NonEpsilonTransitionsOfState_(hps_state_index, current_sorted_type_index);
            // Exercise all valid transitions whose SortedTypeIndex is current_sorted_type_index.
            for (Npda_::TransitionVector_::const_iterator transition_it = non_epsilon_transitions.begin(), transition_it_end = non_epsilon_transitions.end(); transition_it != transition_it_end; ++transition_it)
            {
                Npda_::Transition_ const &transition = *transition_it;
                assert(transition.m_type >= Npda_::Transition_::RETURN);
                assert(transition.m_type <= Npda_::Transition_::POP_STACK);
                assert(Npda_::Transition_::Order::SortedTypeIndex(Npda_::Transition_::Type(transition.m_type)) == current_sorted_type_index);

<|              if(is_defined(generate_debug_spew_code))
/*
                TRISON_CPP_DEBUG_CODE_(
                    DSF_TRANSITION_PROCESSING,
                    *DebugSpewStream() << <{debug_spew_prefix} << "            Processing transition " << ParseTreeNode_::AsString(ParseTreeNode_::Type(transition.m_type)) << " with transition token " << Token(transition.m_token_index) << " and data ";
                    if (transition.m_data_index == ParseTreeNode_::UNUSED_DATA)
                        *DebugSpewStream() << "<N/A>";
                    else
                        *DebugSpewStream() << transition.m_data_index;
                    *DebugSpewStream() << " and sorted type index " << Npda_::Transition_::Order::SortedTypeIndex(Npda_::Transition_::Type(transition.m_type)) << '\n';
                )
*/

<|              end_if
                ParseTreeNode_ *resulting_hps = NULL;
                // If it's a default transition, there's no need to access the lookahead (except in
                // a certain case).
                if (transition.m_token_index == Nonterminal::none_)
                {
                    // Logic regarding empty reduction rules -- if this transition is REDUCE for an empty reduction rule
                    // and the lookahead is the nonterminal for that REDUCE action, then don't reduce, since that
                    // would produce an infinite loop.  There is a case where it's not necessary to access the lookahead:
                    // if this HPS is the child of a REDUCE action for the same nonterminal, then we know the lookahead
                    // is that nonterminal, so it's not necessary to check the lookahead (we don't want to access the
                    // lookahead unnecessarily).  But it's not an if-and-only-if condition; we could have just REDUCE'd
                    // that nonterminal but the HPS has no parent because the trunk action was executed and then popped,
                    // meaning that the parent of this HPS would be the parse tree root.
                    bool take_action = true;
                    assert(hps.m_parent_node != NULL);
                    if (transition.m_type == Npda_::Transition_::REDUCE)
                    {
                        Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[transition.m_data_index];
                        bool is_empty_reduction_rule = rule.m_token_count == 0;
                        bool just_reduced_this_nonterminal = hps.m_parent_node->m_spec.m_type == ParseTreeNode_::REDUCE && hps.m_parent_node->m_spec.m_single_data == rule.m_reduction_nonterminal_token_id;
                        // The fancy logical construction here is to avoid accessing the lookahead unless necessary
                        // (and technically this is not optimal, since really when executing the trunk actions,
                        // the information of "parent is REDUCE and the reduction rule nonterminal is this one"
                        // is lost in the current implementation.
                        if (is_empty_reduction_rule &&
                            (just_reduced_this_nonterminal ||
                             rule.m_reduction_nonterminal_token_id == hps.LookaheadTokenId(*this))) // lookahead is this nonterminal
                        {
<|                          if(is_defined(generate_debug_spew_code))
                            TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << <{debug_spew_prefix} << "            Skipping default action REDUCE on empty reduction rule because the lookahead matches the reduction nonterminal.\n")
<|                          end_if
                            take_action = false;
                        }
                    }

                    if (take_action)
                    {
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << <{debug_spew_prefix} << "            Exercising transition without accessing lookahead... ")
<|                      end_if
                        resulting_hps = TakeHypotheticalActionOnHPS_(hps, ParseTreeNode_::Type(transition.m_type), transition.m_data_index);
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << '\n')
<|                      end_if
                    }
                }
                // Otherwise, the lookahead must be accessed.
                else
                {
                    Token::Id lookahead_token_id = hps.LookaheadTokenId(*this);
                    if (transition.m_token_index == lookahead_token_id)
                    {
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << <{debug_spew_prefix} << "            Exercising transition using lookahead " << Token(lookahead_token_id) << " ... ")
<|                      end_if
                        resulting_hps = TakeHypotheticalActionOnHPS_(hps, ParseTreeNode_::Type(transition.m_type), transition.m_data_index);
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << '\n')
<|                      end_if
                    }
                }
                if (resulting_hps != NULL)
                    m_hypothetical_state_->m_new_hps_queue.push_back(resulting_hps);
            }
        }
    }

    // Take new hps-es and clear old ones.
    assert(!m_hypothetical_state_->m_new_hps_queue.empty());
<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_HPS_REMOVE_DEFUNCT, *DebugSpewStream() << <{debug_spew_prefix} << "    Removing defunct HPSes...\n")
<|  end_if
    for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ *hps = *hps_it;
        if (hps != NULL)
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(
                DSF_HPS_REMOVE_DEFUNCT,
                hps->Print(*DebugSpewStream(), this, DebugSpewPrefix(), 2);
            )
<|          end_if
            m_hypothetical_state_->DeleteBranch(hps);
        }
    }
    m_hypothetical_state_->m_hps_queue.clear();
    std::swap(m_hypothetical_state_->m_hps_queue, m_hypothetical_state_->m_new_hps_queue);
    assert(m_hypothetical_state_->m_new_hps_queue.empty());
}

<{class_name}::Token::Data <{class_name}::ExecuteReductionRule_ (std::uint32_t const rule_index_, TokenStack_ const &token_stack)<{if(!is_defined(enable_reduction_rule_exceptions))} throw()<{end_if}
{
    assert(rule_index_ < Grammar_::ms_rule_count_);
    switch (rule_index_)
    {
        default:
            assert(false && "this should never happen");
            return <{token_data_default};

<|      loop(i, _rule_count)
        case <{i}:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack.size());
<|          loop(j, _rule_token_table_count[i])
<|          if(_rule_token_assigned_id[_rule_token_table_offset[i]+j] != "")
            <{if(_rule_token_assigned_type[_rule_token_table_offset[i]+j] != "")}<{_rule_token_assigned_type[_rule_token_table_offset[i]+j]}<{else}<{token_data_type}<{end_if} <{_rule_token_assigned_id[_rule_token_table_offset[i]+j]}(<{if(_rule_token_assigned_type[_rule_token_table_offset[i]+j] != "")}<{custom_token_data_type_cast}<<{_rule_token_assigned_type[_rule_token_table_offset[i]+j]}>(token_stack[token_stack.size()-<{_rule_token_count[i]-j}].m_data)<{else}token_stack[token_stack.size()-<{_rule_token_count[i]-j}].m_data<{end_if});
<|          end_if
<|          end_loop
<|          _rule_code[i]
            break;
        }

<|      end_loop
    }

<|  if(!is_defined(dont_assert_if_reduction_rule_code_doesnt_return))
<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_PROGRAMMER_ERROR, *DebugSpewStream() << "PROGRAMMER ERROR: No value returned from reduction rule code block; rule " << rule_index_ << ": " << Grammar_::ms_rule_table_[rule_index_].m_description << '\n')
<|  end_if
    assert(false && "no value returned from reduction rule code block");
<|  end_if
    return <{token_data_default};
}

<|if(is_defined(generate_debug_spew_code))
void <{class_name}::PrintParserStatus_ (std::ostream &out) const
{
    assert(m_hypothetical_state_->m_root != NULL);

    // TODO: Print full stack (this is quite a lot)
    out << <{debug_spew_prefix} << "Realized state branch node stacks are (each listed bottom to top):\n";
    for (BranchVector_::const_iterator it = m_realized_state_->BranchVectorStack().back().begin(),
                                       it_end = m_realized_state_->BranchVectorStack().back().end();
         it != it_end;
         ++it)
    {
        Branch_ const &branch = *it;
        out << <{debug_spew_prefix} << "    (";
        branch.StatePtr()->PrintRootToLeaf(out, IdentityTransform_<Npda_::StateIndex_>);
        out << ")\n";
    }

    out << <{debug_spew_prefix} << "Max realized lookahead count (so far) is:\n";
    out << <{debug_spew_prefix} << "    " << m_realized_state_->MaxRealizedLookaheadCount();
    if (m_max_allowable_lookahead_count >= 0)
        out << " (max allowable lookahead count is " << m_max_allowable_lookahead_count << ")\n";
    else
        out << " (allowable lookahead count is unlimited)\n";
    out << <{debug_spew_prefix} << "Max realized lookahead queue size (so far) is:\n";
    out << <{debug_spew_prefix} << "    " << m_realized_state_->MaxRealizedLookaheadQueueSize();
    if (m_max_allowable_lookahead_queue_size >= 0)
        out << " (max allowable lookahead queue size is " << m_max_allowable_lookahead_queue_size << ")\n";
    else
        out << " (allowable lookahead queue size is unlimited)\n";
    out << <{debug_spew_prefix} << "Max realized parse tree depth (so far) is:\n";
    out << <{debug_spew_prefix} << "    " << m_hypothetical_state_->MaxRealizedParseTreeDepth();
    if (m_max_allowable_parse_tree_depth >= 0)
        out << " (max allowable parse tree depth is " << m_max_allowable_parse_tree_depth << ")\n";
    else
        out << " (allowable parse tree depth is unlimited)\n";
    out << <{debug_spew_prefix} << "Has-encountered-error-state (so far) is:\n";
    out << <{debug_spew_prefix} << "    " << (m_realized_state_->HasEncounteredErrorState() ? "true" : "false") << '\n';
    out << <{debug_spew_prefix} << "Realized stack tokens then . delimiter then realized lookahead queue is:\n";
    out << <{debug_spew_prefix} << "    ";
    for (TokenStack_::const_iterator it = m_realized_state_->TokenStack().begin(),
                                     it_end = m_realized_state_->TokenStack().end();
         it != it_end;
         ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << ". ";
    for (TokenQueue_::const_iterator it = m_realized_state_->LookaheadQueue().begin(),
                                     it_end = m_realized_state_->LookaheadQueue().end();
         it != it_end;
         ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << '\n';
    out << <{debug_spew_prefix} << '\n';

    out << <{debug_spew_prefix} << "Parse tree (hypothetical parser states); Notation legend: <real-stack> <hyp-stack> . <hyp-lookaheads> , <real-lookaheads>\n";
    m_hypothetical_state_->m_root->Print(out, this, DebugSpewPrefix());
    out << <{debug_spew_prefix} << '\n';

    out << <{debug_spew_prefix} << "HPS queue:\n";
    for (HPSQueue_::const_iterator it = m_hypothetical_state_->m_hps_queue.begin(), it_end = m_hypothetical_state_->m_hps_queue.end(); it != it_end; ++it)
    {
        ParseTreeNode_ *hps = *it;
        //assert(hps != NULL);
        if (hps != NULL)
            hps->Print(out, this, DebugSpewPrefix(), 1);
    }
}

<|end_if
// ////////////////////////////////////////////////////////////////////////////
// <{class_name}::RealizedState_
// ////////////////////////////////////////////////////////////////////////////

<{class_name}::RealizedState_::RealizedState_ (Npda_::StateIndex_ initial_state)
    :   m_max_realized_lookahead_count(0)
    ,   m_max_realized_lookahead_queue_size(0)
    ,   m_has_encountered_error_state(false)
{
    Initialize(initial_state);
}

void <{class_name}::RealizedState_::PushBackLookahead (Token const &lookahead, HPSQueue_ const &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    m_lookahead_queue.push_back(lookahead);
    UpdateMaxRealizedLookaheadCount();
}

<{class_name}::Token <{class_name}::RealizedState_::PopStack ()
{
    assert(!m_token_stack.empty());

    Token popped_token(m_token_stack.back());
    m_token_stack.pop_back();

    assert(!m_branch_vector_stack.empty());
    m_branch_vector_stack.pop_back();

    assert(m_branch_vector_stack.size() == m_token_stack.size());

    return popped_token;
}

void <{class_name}::RealizedState_::ReplaceTokenStackTopWith (Token const &replacement)
{
    assert(!m_token_stack.empty());
//    m_token_stack.back() = replacement;
    m_token_stack.pop_back();
    m_token_stack.push_back(replacement);
}

<{class_name}::Token <{class_name}::RealizedState_::PopFrontLookahead (HPSQueue_ &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    assert(!m_lookahead_queue.empty());
    // Because the contents of m_lookahead_queue are changing, and each hps's
    // m_realized_lookahead_cursor is an index into that queue, each must be updated.
    for (HPSQueue_::iterator hps_it = hps_queue.begin(), hps_it_end = hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ &hps = **hps_it;
        if (hps.m_realized_lookahead_cursor > 0);
            --hps.m_realized_lookahead_cursor;
    }
    Token retval(m_lookahead_queue.front());
    m_lookahead_queue.pop_front();
    return retval;
}

void <{class_name}::RealizedState_::StealTokenStackTop (<{token_data_type} *&return_token)
{
    assert(return_token != NULL);
    assert(!m_token_stack.empty());
    *return_token = m_token_stack.back().m_data;
    // Assign the token default so that the actual return token isn't destroyed when the parser is destroyed.
    m_token_stack.back().m_data = <{token_data_default};
}

// void <{class_name}::RealizedState_::ExecuteAction (Npda_::Transition_::Type action, ActionData_ action_data)
// {
// }

void <{class_name}::RealizedState_::ExecuteActionReduce (Grammar_::Rule_ const &rule, Token::Data const &reduced_nonterminal_token_data, HPSQueue_ &hps_queue)
{
    for (std::uint32_t i = 0; i < rule.m_token_count; ++i)
        PopStack();
    // Push the reduced nonterminal token data onto the front of the lookahead queue
    PushFrontLookahead(Token(rule.m_reduction_nonterminal_token_id, reduced_nonterminal_token_data), hps_queue);
}

void <{class_name}::RealizedState_::ExecuteActionShift (BranchVector_ const &shifted_branch_vector, HPSQueue_ &hps_queue)
{
    // Ensure that each of the branch nodes in the shifted vector are actually children of
    // the current set of branch nodes.
    assert(!m_branch_vector_stack.empty());
    // Ensure that the stack is actually consistent with regard to the parent/child relationships.
    for (BranchVector_::const_iterator it = shifted_branch_vector.begin(), it_end = shifted_branch_vector.end(); it != it_end; ++it)
    {
        // Note that m_branch_vector_stack.back() is the top of the branch vector stack.
        assert(std::any_of(m_branch_vector_stack.back().begin(), m_branch_vector_stack.back().end(), [it](Branch_ const &stack_top_branch){ return stack_top_branch == it->Parent(); }));
    }
    // Ensure that there's actually a lookahead.
    assert(!m_lookahead_queue.empty());

    // Push onto the branch node stack.
    m_branch_vector_stack.push_back(shifted_branch_vector);
    // Push the token onto the stack.
    m_token_stack.push_back(m_lookahead_queue.front());
    // Pop the shifted lookahead from the queue
    PopFrontLookahead(hps_queue);
}

void <{class_name}::RealizedState_::ExecuteActionInsertLookaheadError (HPSQueue_ &hps_queue)
{
    PushFrontLookahead(Token(Terminal::ERROR_), hps_queue);
    SetHasEncounteredErrorState();
}

void <{class_name}::RealizedState_::ExecuteActionDiscardLookahead (HPSQueue_ &hps_queue)
{
    assert(!m_lookahead_queue.empty());
    PopFrontLookahead(hps_queue);
}

void <{class_name}::RealizedState_::PrintStackAndLookaheads (std::ostream &out) const
{
    for (TokenStack_::const_iterator it = TokenStack().begin(), it_end = TokenStack().end(); it != it_end; ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << '.';
    for (TokenQueue_::const_iterator it = LookaheadQueue().begin(), it_end = LookaheadQueue().end(); it != it_end; ++it)
    {
        Token const &token = *it;
        out << ' ' << token;
    }
}

void <{class_name}::RealizedState_::ClearStack ()
{
    m_branch_vector_stack.clear();
    m_token_stack.clear();
}

void <{class_name}::RealizedState_::Reinitialize (Npda_::StateIndex_ initial_state)
{
    // Clear the stack(s) and reset the error state.
    ClearStack();
    m_has_encountered_error_state = false;
    // But preserve m_lookahead_queue, m_max_realized_lookahead_count, and m_max_realized_lookahead_queue_size

    Initialize(initial_state);
}

void <{class_name}::RealizedState_::Initialize (Npda_::StateIndex_ initial_state)
{
    assert(m_branch_vector_stack.empty());
    assert(m_token_stack.empty());

    BranchVector_ initial_branch_vector;
<|  if(is_defined(generate_debug_spew_code))
    // The Nonterminal::none_ is just a dummy Token::Id to go along with initial_state.
    initial_branch_vector.emplace_back(Branch_(BranchState_::CreateOrphan(initial_state), BranchTokenId_::CreateOrphan(Nonterminal::none_)));
<|  else
    initial_branch_vector.emplace_back(Branch_(BranchState_::CreateOrphan(initial_state)));
<|  end_if
    // TODO: This probably should be emplace_back
    m_branch_vector_stack.push_back(initial_branch_vector);

    // Put a dummy token in to correspond with the start state.
    m_token_stack.push_back(Token(Nonterminal::none_));
}

void <{class_name}::RealizedState_::PushFrontLookahead (Token const &lookahead, HPSQueue_ &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    m_lookahead_queue.push_front(lookahead);
    // Because the contents of m_lookahead_queue_ are changing, and each hps's
    // m_realized_lookahead_cursor is an index into that queue, each must be updated.
    for (HPSQueue_::iterator hps_it = hps_queue.begin(), hps_it_end = hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ &hps = **hps_it;
        ++hps.m_realized_lookahead_cursor;
    }
    UpdateMaxRealizedLookaheadCount();
}

void <{class_name}::RealizedState_::UpdateMaxRealizedLookaheadCount ()
{
    // Subtract the number of parser-generated tokens from the length of m_lookahead_queue.
    std::size_t parser_generated_token_count = 0;
    for ( ; parser_generated_token_count < m_lookahead_queue.size(); ++parser_generated_token_count)
    {
        Token const &lookahead = m_lookahead_queue[parser_generated_token_count];
        if (IsScannerGeneratedTokenId(lookahead.m_id))
            break;
    }
    m_max_realized_lookahead_count = std::max(m_max_realized_lookahead_count, m_lookahead_queue.size() - parser_generated_token_count);

    m_max_realized_lookahead_queue_size = std::max(m_max_realized_lookahead_queue_size, m_lookahead_queue.size());
}

// ////////////////////////////////////////////////////////////////////////////
// <{class_name}::HypotheticalState_
// ////////////////////////////////////////////////////////////////////////////

<{class_name}::HypotheticalState_::HypotheticalState_ (std::uint32_t initial_state)
{
    m_root = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::ROOT));

    ParseTreeNode_ *hps             = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::HPS));
<|  if(is_defined(generate_debug_spew_code))
    hps->m_hypothetical_head        = Branch_(BranchState_::CreateOrphan(initial_state), BranchTokenId_::CreateOrphan(Nonterminal::none_));
<|  else
    hps->m_hypothetical_head        = Branch_(BranchState_::CreateOrphan(initial_state));
<|  end_if

    m_root->AddChild(hps);
    m_hps_queue.push_back(hps);
    m_max_realized_parse_tree_depth = 0;
}

<{class_name}::HypotheticalState_::~HypotheticalState_ ()
{
    m_hps_queue.clear();
    m_new_hps_queue.clear();

    delete m_root;
    m_root = NULL;
}

bool <{class_name}::HypotheticalState_::MinAndMaxRealizedLookaheadCursorsAreEqual () const
{
    std::uint32_t min;
    std::uint32_t max;
    ComputeMinAndMaxRealizedLookaheadCursors(&min, &max);
    return min == max;
}

bool <{class_name}::HypotheticalState_::HasExceededMaxAllowableParseTreeDepth (std::int64_t max_allowable_parse_tree_depth) const
{
    // If the limit is negative, then excess is not possible.
    return max_allowable_parse_tree_depth >= 0 && std::int64_t(ParseTreeDepth()) > max_allowable_parse_tree_depth;
}

void <{class_name}::HypotheticalState_::DeleteBranch (ParseTreeNode_ *branch_node)
{
    assert(!branch_node->IsRoot());

    // Find the most root-ward ancestor that is an only child that isn't the root node.
    ParseTreeNode_ *branch_root = branch_node->BranchRoot();
    assert(branch_root != NULL);
    assert(!branch_root->IsRoot());
    assert(branch_root->HasParent());

    branch_root->RemoveFromParent();
    branch_node->NullifyHPSNodeDescendantsInHPSQueue(m_hps_queue);
    delete branch_root;
}

void <{class_name}::HypotheticalState_::DestroyParseTree ()
{
    assert(m_new_hps_queue.empty());
    // Clear all HPSes, which represent the leaf nodes of the parse tree.
    m_hps_queue.clear();
    // Delete the parse tree root, which deletes all nodes.
    delete m_root;
    // At this point, the parse tree has been destroyed.  Create a new root node.
    m_root = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::ROOT));
}

void <{class_name}::HypotheticalState_::ComputeMinAndMaxRealizedLookaheadCursors (std::uint32_t *min, std::uint32_t *max) const
{
    if (min != NULL)
        *min = std::numeric_limits<std::uint32_t>::max();
    if (max != NULL)
        *max = std::numeric_limits<std::uint32_t>::min();

    for (HPSQueue_::const_iterator hps_it = m_hps_queue.begin(), hps_it_end = m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        // Skip nullified HPS nodes.
        if (*hps_it == NULL)
            continue;

        ParseTreeNode_ const &hps = **hps_it;
        if (min != NULL && hps.m_realized_lookahead_cursor < *min)
            *min = hps.m_realized_lookahead_cursor;
        if (max != NULL && hps.m_realized_lookahead_cursor > *max)
            *max = hps.m_realized_lookahead_cursor;
    }
}

std::uint32_t <{class_name}::HypotheticalState_::ParseTreeDepth () const
{
    std::uint32_t parse_tree_depth = 0;

    for (HPSQueue_::const_iterator hps_it = m_hps_queue.begin(), hps_it_end = m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        // Skip nullified HPS nodes.
        if (*hps_it == NULL)
            continue;

        ParseTreeNode_ const &hps = **hps_it;
        std::uint32_t branch_depth = hps.m_depth - m_root->m_depth;
        if (branch_depth > parse_tree_depth)
            parse_tree_depth = branch_depth;
    }

    // Update m_max_realized_parse_tree_depth
    if (parse_tree_depth > m_max_realized_parse_tree_depth)
        m_max_realized_parse_tree_depth = parse_tree_depth;

    return parse_tree_depth;
}

// ////////////////////////////////////////////////////////////////////////////
// <{class_name}::ParseTreeNode_
// ////////////////////////////////////////////////////////////////////////////

<|if(is_defined(generate_debug_spew_code))
char const *<{class_name}::ParseTreeNode_::AsString (Type type)
{
    static char const *const LOOKUP_TABLE[COUNT_] =
    {
        "ROOT",
        "RETURN",
        "REDUCE",
        "SHIFT",
        "INSERT_LOOKAHEAD_ERROR",
        "DISCARD_LOOKAHEAD",
        "POP_STACK",
        "HPS"
    };
    assert(std::uint32_t(type) < COUNT_);
    return LOOKUP_TABLE[std::uint32_t(type)];
}

<|end_if
bool <{class_name}::ParseTreeNode_::ParseTreeNodeOrder::operator () (<{class_name}::ParseTreeNode_ const *lhs, <{class_name}::ParseTreeNode_ const *rhs) const
{
    assert(lhs != NULL);
    assert(rhs != NULL);
    assert(lhs->m_spec.m_type == rhs->m_spec.m_type); // ParseTreeNodeSet should contain only nodes of the same type.
    // for HPS, their contents must be compared.
    if (lhs->m_spec.m_type == HPS)
    {
        assert(lhs->m_child_nodes.empty());
        assert(rhs->m_child_nodes.empty());
        // hps-es are equal if their m_realized_lookahead_cursor and m_hypothetical_lookahead_token_id_queue members are.
        if (lhs->m_realized_lookahead_cursor != rhs->m_realized_lookahead_cursor)
            return lhs->m_realized_lookahead_cursor < rhs->m_realized_lookahead_cursor;
        else if (lhs->m_hypothetical_head.StatePtr() != rhs->m_hypothetical_head.StatePtr())
            return lhs->m_hypothetical_head.StatePtr() < rhs->m_hypothetical_head.StatePtr();
        else
            return std::lexicographical_compare(
                lhs->m_hypothetical_lookahead_token_id_queue.begin(), lhs->m_hypothetical_lookahead_token_id_queue.end(),
                rhs->m_hypothetical_lookahead_token_id_queue.begin(), rhs->m_hypothetical_lookahead_token_id_queue.end(),
                CompareTokenId_
            );
    }
    // For REDUCE, their contents must be compared.
    else if (lhs->m_spec.m_type == REDUCE)
    {
        // m_single_data contains the reduction rule index.
        Grammar_::Rule_ const &lhs_rule = Grammar_::ms_rule_table_[lhs->m_spec.m_single_data];
        Grammar_::Rule_ const &rhs_rule = Grammar_::ms_rule_table_[rhs->m_spec.m_single_data];
        // Sort first by rule precedence, then by rule index (lower has higher priority).
        if (Grammar_::ms_precedence_table_[lhs_rule.m_precedence_index].m_level != Grammar_::ms_precedence_table_[rhs_rule.m_precedence_index].m_level)
            return Grammar_::ms_precedence_table_[lhs_rule.m_precedence_index].m_level > Grammar_::ms_precedence_table_[rhs_rule.m_precedence_index].m_level;
        else // Sort based on rule index.
            return lhs->m_spec.m_single_data < rhs->m_spec.m_single_data;
    }
    // Otherwise just use pointer value.
    else
        return lhs < rhs;
}

<|if(0)
<|if(is_defined(generate_debug_spew_code))
std::set<<{class_name}::ParseTreeNode_*> <{class_name}::ParseTreeNode_::ms_active_pointer_set;

<|end_if
<|end_if
<{class_name}::ParseTreeNode_::~ParseTreeNode_ ()
{
<|  if(0)
<|  if(is_defined(generate_debug_spew_code))
    assert(ms_active_pointer_set.find(this) != ms_active_pointer_set.end());
    ms_active_pointer_set.erase(this);

<|  end_if
<|  end_if
    // TODO: figure out if stack element tokens should be thrown away
    // TODO: figure out if local lookahead queue tokens should be thrown away
    // TODO: are they actually uninitialized (default value)?
    for (ChildMap::iterator it = m_child_nodes.begin(), it_end = m_child_nodes.end(); it != it_end; ++it)
    {
        ParseTreeNodeSet &child_node_set = it->second;
        for (ParseTreeNodeSet::iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            ParseTreeNode_ *child = *child_it;
            assert(child != NULL);
            assert(child->m_parent_node == this);
            delete child;
        }
        child_node_set.clear(); // not strictly necessary, but is cleaner.
    }
}

bool <{class_name}::ParseTreeNode_::HasTrunkChild () const
{
    if (m_spec.m_type != ROOT || m_child_nodes.size() != 1)
        return false;
    ParseTreeNodeSet const &single_type_child_node_set = m_child_nodes.begin()->second;
    if (single_type_child_node_set.size() != 1)
        return false;
    ParseTreeNode_ *single_child = *single_type_child_node_set.begin();
    assert(single_child != NULL);
    assert(single_child->m_spec.m_type != ROOT);
    return single_child->m_spec.m_type != HPS;
}

<{class_name}::ParseTreeNode_ *<{class_name}::ParseTreeNode_::PopTrunkChild ()
{
    assert(HasTrunkChild());
    ParseTreeNode_ *trunk_child = *m_child_nodes.begin()->second.begin();
    assert(trunk_child != NULL);
    assert(trunk_child->m_parent_node == this);
    // Reassign the children of the trunk child to this node (root).
    m_child_nodes = trunk_child->m_child_nodes;
    trunk_child->m_child_nodes.clear();
    // Set the reassigned child nodes' parent to be this node (root).
    for (ChildMap::iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
    {
        ParseTreeNodeSet &child_node_set = child_map_it->second;
        for (ParseTreeNodeSet::iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            ParseTreeNode_ *child = *child_it;
            assert(child != NULL);
            child->m_parent_node = this;
        }
    }
    trunk_child->m_parent_node = NULL;
    return trunk_child;
}

bool <{class_name}::ParseTreeNode_::HasExactlyOneChild () const
{
    return m_child_nodes.size() == 1 && m_child_nodes.begin()->second.size() == 1;
}

<{class_name}::ParseTreeNode_ *<{class_name}::ParseTreeNode_::BranchRoot ()
{
    assert(!IsRoot());
    assert(HasParent());
    ParseTreeNode_ *node = this;
    while (node->HasParent() && !node->m_parent_node->IsRoot() && node->m_parent_node->HasExactlyOneChild())
    {
        node = node->m_parent_node;
        assert(node->m_spec.m_type != HPS);
    }
    return node;
}

<{class_name}::Token::Id <{class_name}::ParseTreeNode_::LookaheadTokenId (<{class_name} &parser) const
{
    if (m_hypothetical_lookahead_token_id_queue.empty())
        return parser.Lookahead_(m_realized_lookahead_cursor).m_id;
    else
        return m_hypothetical_lookahead_token_id_queue.front();
}

bool <{class_name}::ParseTreeNode_::IsBlockedHPS () const
{
    assert(m_spec.m_type == HPS);
    if (m_parent_node == NULL)
        return false;
    switch (m_parent_node->m_spec.m_type)
    {
        // Nothing can happen after returning, so this has to be blocking.
        case RETURN:
        case POP_STACK: return true;

        default:        return false;
    }
}

<{class_name}::ParseTreeNode_::PrecedenceLevelRange <{class_name}::ParseTreeNode_::ComputePrecedenceLevelRange (std::uint32_t current_child_depth) const
{
    if (m_spec.m_type == HPS)
    {
        // Need to look back at the rule of the (current_child_depth-1)th ancestor of this node in order
        // to get the correct rule precedence, because that's where the conflict occurred.

        assert(current_child_depth >= 2);
        // These asserts are equivalent to checking that the stack depth is at least 2.
        assert(bool(m_hypothetical_head.StatePtr()));
        assert(bool(m_hypothetical_head.StatePtr()->HasParent()));

        // Thinking of m_hypothetical_head.StatePtr() as the top of the state stack, we want to get the
        // (current_child_depth-1)th element from the top.
        BranchStatePtr_ child_branch_node_ptr = m_hypothetical_head.StatePtr();
        for (std::uint32_t i = 0; i < current_child_depth-2; ++i)
        {
            // This assert checks that the stack depth is sufficient.
            assert(child_branch_node_ptr->HasParent());
            child_branch_node_ptr = child_branch_node_ptr->Parent();
        }
        std::uint32_t state_index = child_branch_node_ptr->Data();

        assert(state_index < Npda_::ms_state_count_);
        Npda_::State_ const &state = Npda_::ms_state_table_[state_index];
        // If there's an associated rule, then use the precedence from that.
        if (state.m_associated_rule_index < Grammar_::ms_rule_count_)
        {
            Grammar_::Rule_ const &associated_rule = Grammar_::ms_rule_table_[state.m_associated_rule_index];
            assert(associated_rule.m_precedence_index < Grammar_::ms_precedence_count_);
            Grammar_::Precedence_ const &rule_precedence = Grammar_::ms_precedence_table_[associated_rule.m_precedence_index];
            return PrecedenceLevelRange(rule_precedence.m_level, rule_precedence.m_level);
        }
        // Otherwise (e.g. a RETURN state), return default precedence.
        else
        {
            Grammar_::Precedence_ const &default_precedence = Grammar_::ms_precedence_table_[0]; // 0 is default precedence.
            return PrecedenceLevelRange(default_precedence.m_level, default_precedence.m_level);
        }
    }
    else if (m_spec.m_type == REDUCE)
    {
        std::uint32_t reduction_rule_index = m_spec.m_single_data;
        Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduction_rule_index];
        assert(reduction_rule.m_precedence_index < Grammar_::ms_precedence_count_);
        Grammar_::Precedence_ const &rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
        return PrecedenceLevelRange(rule_precedence.m_level, rule_precedence.m_level);
    }
    else if (m_spec.m_type == SHIFT)
    {
        PrecedenceLevelRange retval(std::numeric_limits<std::int32_t>::max(), std::numeric_limits<std::int32_t>::min());
        assert(!m_child_nodes.empty());
        // The range is the smallest range encompassing the range of each child node.
        for (ChildMap::const_iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
        {
            ParseTreeNodeSet const &child_node_set = child_map_it->second;
            for (ParseTreeNodeSet::const_iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
            {
                assert(*child_it != NULL);
                ParseTreeNode_ const &child = **child_it;
                PrecedenceLevelRange child_precedence_level_range(child.ComputePrecedenceLevelRange(current_child_depth+1));
                retval.first = std::min(retval.first, child_precedence_level_range.first);
                retval.second = std::max(retval.second, child_precedence_level_range.second);
            }
        }
        assert(retval.first <= retval.second);
        return retval;
    }
    else
    {
        // TODO: Probably need to do something to determine if this can't happen or prevent it.
        assert(false);
        return PrecedenceLevelRange(0, 0);
    }
}

bool <{class_name}::ParseTreeNode_::HasShiftReduceConflict (ParseTreeNode_ *&shift, ParseTreeNode_ *&reduce)
{
    ChildMap::iterator shift_children_it = m_child_nodes.find(Spec(SHIFT));
    ChildMap::iterator reduce_children_it = m_child_nodes.find(Spec(REDUCE));
    if (shift_children_it == m_child_nodes.end() || reduce_children_it == m_child_nodes.end())
        return false;

    ParseTreeNodeSet &shift_children = shift_children_it->second;
    ParseTreeNodeSet &reduce_children = reduce_children_it->second;
    assert(shift_children.size() == 1);
    assert(reduce_children.size() == 1);

    shift = *shift_children.begin();
    reduce = *reduce_children.begin();
    return true;
}

void <{class_name}::ParseTreeNode_::AddChild (ParseTreeNode_ *child)
{
    assert(child != NULL);
    assert(child->m_parent_node == NULL);
    assert(child->m_spec.m_type != ROOT);

    m_child_nodes[child->m_spec].insert(child);
    child->m_parent_node = this;
    child->m_depth = m_depth + 1; // Always +1 relative to parent.

    // If this node is SHIFT and the child is HPS, then add the child's NPDA state to this node's
    // m_child_branch_vector.  This is the only situation in which m_child_branch_vector is added to.
    if (m_spec.m_type == SHIFT && child->m_spec.m_type == HPS)
    {
        assert(bool(child->m_hypothetical_head.StatePtr()));
        assert(std::none_of(m_child_branch_vector.begin(), m_child_branch_vector.end(), [child](Branch_ const &node_state){ return node_state.StatePtr() == child->m_hypothetical_head.StatePtr(); }) && "child branch node should not already be in the set");
        m_child_branch_vector.push_back(child->m_hypothetical_head);
    }
}

void <{class_name}::ParseTreeNode_::RemoveChild (ParseTreeNode_ *child)
{
    assert(child != NULL);
    assert(child->m_parent_node == this);
    assert(HasChildrenHavingSpec(child->m_spec));
    assert(m_child_nodes[child->m_spec].find(child) != m_child_nodes[child->m_spec].end());
    m_child_nodes[child->m_spec].erase(child);
    if (m_child_nodes[child->m_spec].empty())
        m_child_nodes.erase(child->m_spec);
    child->m_parent_node = NULL;
    child->m_depth = 0; // Reset.

    // If there are no children and this isn't the root node, remove it from its parent.
    if (m_child_nodes.empty() && m_parent_node != NULL)
        RemoveFromParent();
}

void <{class_name}::ParseTreeNode_::RemoveFromParent ()
{
    assert(m_parent_node != NULL);
    m_parent_node->RemoveChild(this);
}

void <{class_name}::ParseTreeNode_::NullifyHPSNodeDescendantsInHPSQueue (HPSQueue_ &hps_queue) const
{
    if (m_spec.m_type == HPS)
    {
        // NOTE: This is a linear search, which is not as efficient as a different way of handling this.
        HPSQueue_::iterator it = std::find(hps_queue.begin(), hps_queue.end(), this);
        if (it != hps_queue.end())
            *it = NULL;
    }
    for (ChildMap::const_iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
    {
        ParseTreeNodeSet const &child_node_set = child_map_it->second;
        for (ParseTreeNodeSet::const_iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            assert(*child_it != NULL);
            ParseTreeNode_ const &child = **child_it;
            child.NullifyHPSNodeDescendantsInHPSQueue(hps_queue);
        }
    }
}

<{class_name}::ParseTreeNode_ *<{class_name}::ParseTreeNode_::CloneLeafNode () const
{
    ParseTreeNode_ *retval = new ParseTreeNode_(m_spec);
    CloneLeafNodeInto(*retval);
    return retval;
}

void <{class_name}::ParseTreeNode_::CloneLeafNodeInto (<{class_name}::ParseTreeNode_ &orphan_target) const
{
    assert(orphan_target.m_parent_node == NULL);
    assert(m_child_nodes.empty());
    orphan_target.m_spec                                    = m_spec;
    orphan_target.m_hypothetical_head                       = m_hypothetical_head;
    orphan_target.m_hypothetical_lookahead_token_id_queue   = m_hypothetical_lookahead_token_id_queue;
    orphan_target.m_realized_lookahead_cursor               = m_realized_lookahead_cursor;
}

<|if(is_defined(generate_debug_spew_code))
void <{class_name}::ParseTreeNode_::Print (std::ostream &out, <{class_name} const *parser, std::string const &prefix, std::uint32_t indent_level, bool suppress_initial_prefix) const
{
    if (!suppress_initial_prefix)
    {
        out << prefix;
        for (std::uint32_t i = 0; i < indent_level; ++i)
            out << "    ";
    }
    out << AsString(m_spec.m_type) << ' ' << this << " (depth = " << m_depth << ')';
    if (m_spec.m_type == HPS)
    {
        out << (IsBlockedHPS() ? " (    blocked," : " (non-blocked,");
        out << " m_realized_lookahead_cursor = " << m_realized_lookahead_cursor << ')';
    }
    switch (m_spec.m_type)
    {
        case REDUCE:    out << " rule " << m_spec.m_single_data << "; " << Grammar_::ms_rule_table_[m_spec.m_single_data].m_description;  break;
        //case SHIFT:     out << " to (?) state " << m_spec.m_single_data << "; " << Npda_::ms_state_table_[m_spec.m_single_data].m_description; break;
        case SHIFT:     out << ' ' << Token(m_spec.m_single_data); break;
        case POP_STACK: out << ' ' << m_spec.m_single_data << " time(s)";                                                       break;
        default:                                                                                                                break;
    }
    if (bool(m_hypothetical_head.StatePtr()))
        out << ' ' << Npda_::ms_state_table_[m_hypothetical_head.StatePtr()->Data()].m_description << ' ';
    if (m_spec.m_type == HPS)
    {
        assert(bool(m_hypothetical_head.StatePtr()));
        assert(bool(m_hypothetical_head.TokenIdPtr()));

        out << "    (";
        m_hypothetical_head.StatePtr()->PrintRootToLeaf(out, IdentityTransform_<Npda_::StateIndex_>);
        out << "); ";

        m_hypothetical_head.TokenIdPtr()->PrintRootToLeaf(out, TokenName_);
        out << " . ";
        for (std::size_t i = 0; i < m_hypothetical_lookahead_token_id_queue.size(); ++i)
            out << ms_token_name_table_[m_hypothetical_lookahead_token_id_queue[i]] << ' ';
        out << ", ";
        if (parser != NULL)
            for (std::size_t i = m_realized_lookahead_cursor; i < parser->m_realized_state_->LookaheadQueue().size(); ++i)
                out << ms_token_name_table_[parser->m_realized_state_->LookaheadQueue()[i].m_id] << ' ';
        else
            out << "<realized-lookaheads-not-printed>";
    }
    out << '\n';

    // Print children recursively with higher indent level
    for (ChildMap::const_iterator it = m_child_nodes.begin(), it_end = m_child_nodes.end(); it != it_end; ++it)
    {
        ParseTreeNodeSet const &child_node_set = it->second;
        for (ParseTreeNodeSet::const_iterator set_it = child_node_set.begin(), set_it_end = child_node_set.end(); set_it != set_it_end; ++set_it)
            (*set_it)->Print(out, parser, prefix, indent_level+1);
    }
}

<|end_if
// ////////////////////////////////////////////////////////////////////////////
// End of <{class_name}::ParseTreeNode_
// ////////////////////////////////////////////////////////////////////////////

<{class_name}::Token const &<{class_name}::Lookahead_ (TokenQueue_::size_type index)<{if(!is_defined(enable_scan_actions_exceptions))} throw()<{end_if}
{
    while (index >= m_realized_state_->LookaheadQueue().size())
    {
        // This does not require updating the hps-es' m_realized_lookahead_cursor.
        m_realized_state_->PushBackLookahead(Scan_(), m_hypothetical_state_->m_hps_queue);
<|      if(is_defined(generate_debug_spew_code))

        TRISON_CPP_DEBUG_CODE_(DSF_SCANNER_ACTION, *DebugSpewStream() << <{debug_spew_prefix} << "Retrieved token " << m_realized_state_->LookaheadQueue().back() << " from scan actions; pushing token onto back of lookahead queue\n")
<|      end_if
    }
    return m_realized_state_->LookaheadQueue()[index];
}

<{class_name}::ParseTreeNode_ *<{class_name}::TakeHypotheticalActionOnHPS_ (ParseTreeNode_ const &hps, ParseTreeNode_::Type action_type, std::uint32_t action_data)
{
    // TODO: replace individual arguments action_type, action_data with ParseTreeNode_::Spec and just modify that struct below where it needs it.
    assert(hps.m_spec.m_type == ParseTreeNode_::HPS && "Only a HPS type node can take an action");
    assert(hps.m_parent_node != NULL);

    ParseTreeNode_ *new_hps = NULL;

    switch (action_type)
    {
        case ParseTreeNode_::ROOT: {
            assert(false && "ParseTreeNode_::ROOT is an invalid action type.");
            break;
        }
        case ParseTreeNode_::RETURN: {
            new_hps = hps.CloneLeafNode();
            break;
        }
        case ParseTreeNode_::REDUCE: {
            // Execute the appropriate rule on the top tokens in the stack
            std::uint32_t const &rule_index = action_data;
            Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[rule_index];

            // Avoid creating the new hps altogether if it won't be added due to a REDUCE/REDUCE conflict.
            ParseTreeNode_ *existing_reduce_action_node = NULL;
            ParseTreeNode_ *reduce_hps = NULL;
            ParseTreeNode_::Spec action_spec(action_type, action_data);
            if (hps.m_parent_node->HasChildrenHavingSpec(action_spec)) // Check for an existing REDUCE action
            {
                // This may or may not be a conflict.  Need to determine that.

                ParseTreeNode_::ParseTreeNodeSet &reduce_node_set = hps.m_parent_node->ChildrenHavingSpec(action_spec);
                assert(reduce_node_set.size() == 1);
                existing_reduce_action_node = *reduce_node_set.begin();
                assert(existing_reduce_action_node != NULL);
                assert(existing_reduce_action_node->m_spec.m_type == ParseTreeNode_::REDUCE);

                if (true)
                {
                    // TEMP
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "\n\nHIPPO existing_reduce_action_node child nodes:\n\n")
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, PrintParserStatus_(*DebugSpewStream()))
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "\n\n")
                }

                // If the hypothetical action is identical to the existing one, then there's no problem,
                // just add it as a child to the existing one.
                if (existing_reduce_action_node->m_spec.m_single_data == rule_index)
                {
                    new_hps = hps.CloneLeafNode();
                    reduce_hps = new_hps;
                }
                // Otherwise this is a REDUCE/REDUCE conflict
                else
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << <{debug_spew_prefix} << "TakeHypotheticalActionOnHPS_ - REDUCE/REDUCE conflict encountered ... ")

<|                  end_if
                    // If the new REDUCE action beats the existing one in a conflict, just replace the existing one
                    // (replacement instead of creating a new one and deleting the old is an optimization which also
                    // avoids an annoying traversal through m_hypothetical_state_->m_hps_queue).
                    // NOTE: This depends on the fact that a REDUCE node has exactly one HPS child,
                    // which is what these three asserts check.  TODO: maybe make abstractions for these sorts of checks.
                    assert(existing_reduce_action_node->m_child_nodes.size() == 1);
                    assert(existing_reduce_action_node->m_child_nodes.begin()->second.size() == 1);
                    assert((*existing_reduce_action_node->m_child_nodes.begin()->second.begin())->m_spec.m_type == ParseTreeNode_::HPS);
                    if (Grammar_::CompareRuleByPrecedence_(action_data, existing_reduce_action_node->m_spec.m_single_data))
                    {
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "resolving in favor of new hps.")

<|                      end_if
                        reduce_hps = *existing_reduce_action_node->m_child_nodes.begin()->second.begin();
                        assert(reduce_hps != NULL);

                        // Remove the nodes from the ParseTreeNode_ tree.
                        assert(existing_reduce_action_node != NULL);
                        existing_reduce_action_node->RemoveFromParent();
                        reduce_hps->RemoveFromParent();
                        // Modify the nodes.
                        existing_reduce_action_node->m_spec = action_spec; // Replace with the winning reduction rule Spec.
                        hps.CloneLeafNodeInto(*reduce_hps); // NOTE: This modifies the existing hps, so no update of m_hypothetical_state_->m_hps_queue is necessary.
                        // Re-add them to the ParseTreeNode_ tree.
                        existing_reduce_action_node->AddChild(reduce_hps);
                        hps.m_parent_node->AddChild(existing_reduce_action_node);
                    }
                    else
                    {
<|                      if(is_defined(generate_debug_spew_code))
                        TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "resolving in favor of existing hps.")
<|                      else
                        // Resolving in favor of existing HPS.
<|                      end_if
                    }
                    assert(existing_reduce_action_node->m_child_nodes.begin()->second.size() == 1);
                }
            }
            else
            {
                new_hps = hps.CloneLeafNode();
                reduce_hps = new_hps;
            }

            if (reduce_hps != NULL)
            {
                // Pop those stack tokens.
                for (std::uint32_t i = 0; i < rule.m_token_count; ++i)
                {
                    assert(reduce_hps->m_hypothetical_head.HasParent());
                    reduce_hps->m_hypothetical_head = reduce_hps->m_hypothetical_head.Parent();
                }
                // Push the reduced nonterminal token data onto the front of the lookahead queue
                reduce_hps->m_hypothetical_lookahead_token_id_queue.push_front(rule.m_reduction_nonterminal_token_id);
            }

            break;
        }
        case ParseTreeNode_::SHIFT: {
            // Move the front of the lookahead queue to the top of the stack, assigning the appropriate state index.
            std::uint32_t const &state_index = action_data;
            // TODO: probably make "Shift" method for ParseTreeNode_ to do all this bookkeeping and parallel LookaheadTokenId tracking.
            new_hps = hps.CloneLeafNode();
            Token::Id lookahead_token_id = new_hps->LookaheadTokenId(*this);
            // Create a new Branch_ and link it to the parent node's.
<|          if(is_defined(generate_debug_spew_code))
            new_hps->m_hypothetical_head = Branch_(BranchState_::CreateWithParent(hps.m_hypothetical_head.StatePtr(), state_index), BranchTokenId_::CreateWithParent(hps.m_hypothetical_head.TokenIdPtr(), lookahead_token_id));
<|          else
            new_hps->m_hypothetical_head = Branch_(BranchState_::CreateWithParent(hps.m_hypothetical_head.StatePtr(), state_index));
<|          end_if
            assert(new_hps->m_hypothetical_head.HasParent());
            assert(new_hps->m_hypothetical_head.Parent() == hps.m_hypothetical_head);

            // Store the lookahead token id in action_data so it can printed.
            action_data = std::uint32_t(lookahead_token_id);
            if (new_hps->m_hypothetical_lookahead_token_id_queue.empty())
                ++new_hps->m_realized_lookahead_cursor;
            else
                new_hps->m_hypothetical_lookahead_token_id_queue.pop_front();
            break;
        }
        case ParseTreeNode_::INSERT_LOOKAHEAD_ERROR: {
            new_hps = hps.CloneLeafNode();
            new_hps->m_hypothetical_lookahead_token_id_queue.push_front(Terminal::ERROR_);
            break;
        }
        case ParseTreeNode_::DISCARD_LOOKAHEAD: {
            new_hps = hps.CloneLeafNode();
            if (new_hps->m_hypothetical_lookahead_token_id_queue.empty())
                ++new_hps->m_realized_lookahead_cursor;
            else
                new_hps->m_hypothetical_lookahead_token_id_queue.pop_front();
            break;
        }
        case ParseTreeNode_::POP_STACK: {
            // TODO: make separate action nodes for each pop, instead of using action data,
            // since for example two branches may agree on popping at least once, even if
            // one of them is killed later.
            std::uint32_t const &pop_count = action_data;
            assert(pop_count == 1 || pop_count == 2);
            // Check if there are actually enough stack elements to pop successfully.
            // If not, then don't create an HPS, and break early.
            if (pop_count >= hps.m_hypothetical_head.StatePtr()->BranchLength())
            {
                new_hps = NULL;
                break;
            }

            new_hps = hps.CloneLeafNode();
            for (std::uint32_t i = 0; i < pop_count; ++i)
            {
                assert(new_hps->m_hypothetical_head.HasParent());
                new_hps->m_hypothetical_head = new_hps->m_hypothetical_head.Parent();
            }
            if (pop_count == 2)
                new_hps->m_hypothetical_lookahead_token_id_queue.push_front(Terminal::ERROR_);
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "creating HPS to be child of POP_STACK node... ")
<|          end_if
            break;
        }
        case ParseTreeNode_::HPS: {
            assert(false && "ParseTreeNode_::HPS is an invalid action type.");
            break;
        }
        default: {
            assert(false && "invalid ParseTreeNode_::Type");
            break;
        }
    }

    if (new_hps != NULL)
    {
        assert(new_hps->m_parent_node == NULL);

        ParseTreeNode_ *action_node = NULL;

        // Ensure the action node exists, creating it if necessary.
        ParseTreeNode_::Spec action_spec(action_type, action_data);
        if (hps.m_parent_node->HasChildrenHavingSpec(action_spec))
        {
            ParseTreeNode_::ParseTreeNodeSet &children_of_action_type = hps.m_parent_node->ChildrenHavingSpec(action_spec);
            assert(children_of_action_type.size() == 1);
            action_node = *children_of_action_type.begin();
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "using existing action node of type " << ParseTreeNode_::AsString(action_spec.m_type) << "... ")

<|          end_if
            // If the new hps already exists (can only happen as a child of POP_STACK), then don't add it.
            if (action_type == ParseTreeNode_::POP_STACK && action_node->HasChildrenHavingSpec(new_hps->m_spec))
            {
                ParseTreeNode_::ParseTreeNodeSet const &child_hps_set = action_node->ChildrenHavingSpec(new_hps->m_spec);
                if (child_hps_set.find(new_hps) != child_hps_set.end())
                {
<|                  if(is_defined(generate_debug_spew_code))
                    TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "not adding duplicate HPS as child of POP_STACK node... ")
<|                  end_if
                    delete new_hps;
                    new_hps = NULL;
                }
            }
        }
        else
        {
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "creating new action node of type " << ParseTreeNode_::AsString(action_spec.m_type) << "... ")
<|          end_if
            action_node = new ParseTreeNode_(action_spec);
<|          if(is_defined(generate_debug_spew_code))
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "(action_node = " << action_node << ") ")
<|          end_if
            hps.m_parent_node->AddChild(action_node);
        }

        if (new_hps != NULL)
            action_node->AddChild(new_hps);
    }

    return new_hps;
}

void <{class_name}::CreateParseTreeFromRealizedState_ ()
{
    BranchVector_ const &reconstruct_branch_vector = m_realized_state_->BranchVectorStack().back();

    // Add HPS nodes for each branch in the top of the realized state stack.
    assert(!reconstruct_branch_vector.empty());
<|  if(is_defined(generate_debug_spew_code))
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << "        Reconstructing branches:\n")
<|  end_if
    for (BranchVector_::const_iterator it = reconstruct_branch_vector.begin(), it_end = reconstruct_branch_vector.end(); it != it_end; ++it)
    {
        Branch_ const &reconstruct_branch = *it;
<|      if(is_defined(generate_debug_spew_code))
        TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << <{debug_spew_prefix} << "            " << reconstruct_branch.StatePtr() << '\n')
<|      end_if

        ParseTreeNode_ *hps             = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::HPS));
        hps->m_hypothetical_head        = reconstruct_branch;

        m_hypothetical_state_->m_root->AddChild(hps);
        m_hypothetical_state_->m_hps_queue.push_back(hps);
    }
}

void <{class_name}::ClearStack_ ()
{
    if (m_realized_state_ != NULL)
    {
        // TODO: Could print the m_realized_state_ m_branch_vector_stack element being popped.
        while (!m_realized_state_->TokenStack().empty())
            ThrowAwayToken_(m_realized_state_->PopStack());
    }

    delete m_hypothetical_state_;
    m_hypothetical_state_ = NULL;
}

void <{class_name}::CleanUpAllInternals_ ()
{
    if (m_realized_state_ != NULL)
    {
        // TODO: Could print the m_realized_state_ m_branch_vector_stack element being popped.
        while (!m_realized_state_->TokenStack().empty())
            ThrowAwayToken_(m_realized_state_->PopStack());

        while (!m_realized_state_->LookaheadQueue().empty())
            ThrowAwayToken_(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue));

        // Note that this implicitly resets the error state (since that's tracked by m_realized_state_).
        delete m_realized_state_;
        m_realized_state_ = NULL;
    }

    delete m_hypothetical_state_;
    m_hypothetical_state_ = NULL;
}

// ////////////////////////////////////////////////////////////////////////////
// <{class_name}::Grammar_
// ////////////////////////////////////////////////////////////////////////////

<|include("trison.cpp.npda.grammar.implementation.codespec")

// ////////////////////////////////////////////////////////////////////////////
// <{class_name}::Npda_
// ////////////////////////////////////////////////////////////////////////////

<|include("trison.cpp.npda.npda.implementation.codespec")
