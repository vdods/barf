// DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY
// using_unique_ptr_parser.cpp generated by trison
// from using_unique_ptr_parser.trison using trison.cpp.targetspec and trison.cpp.implementation.codespec
// DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY ! DO NOT MODIFY

#include "using_unique_ptr_parser.hpp"



#define TRISON_CPP_DEBUG_CODE_(flags, spew_code) if (DebugSpewIsEnabled() && ((flags) & ActiveDebugSpewFlags()) != 0) { spew_code; }

#include <algorithm>
#include <limits>
#include <sstream>
#include <utility>


#line 47 "../using_unique_ptr_parser.trison"

#include "using_unique_ptr_ast.hpp"
#include "using_unique_ptr_scanner.hpp"

template <typename TargetUniquePtr_, typename Source_, typename Delete_>
TargetUniquePtr_ static_move_cast (std::unique_ptr<Source_,Delete_> &&p) {
    return TargetUniquePtr_{static_cast<typename TargetUniquePtr_::element_type*>(p.release())};
}

#line 29 "../using_unique_ptr_parser.cpp"

Parser::Parser ()
{
    m_max_allowable_lookahead_count = 1;
    m_max_allowable_lookahead_queue_size = 2;
    m_max_allowable_parse_tree_depth = 64;
    m_realized_state_ = NULL;
    m_hypothetical_state_ = NULL;
    SetDebugSpewStream(NULL);
    SetActiveDebugSpewFlags(DSF__ALL);


#line 56 "../using_unique_ptr_parser.trison"


#line 45 "../using_unique_ptr_parser.cpp"
}

Parser::~Parser ()
{
    // Perform all the internal cleanup needed.
    CleanUpAllInternals_();
    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing destructor actions\n")


#line 58 "../using_unique_ptr_parser.trison"


#line 58 "../using_unique_ptr_parser.cpp"
}

bool Parser::IsAtEndOfInput ()
{
    return true; // TEMP
}

std::string Parser::DebugSpewPrefix () const
{
    std::ostringstream out;
    out << "Parser: ";
    return out.str();
}

void Parser::ResetForNewInput ()
{
    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing reset-for-new-input actions\n")

    // Perform all the internal cleanup needed.
    CleanUpAllInternals_();
}

Parser::ParserReturnCode Parser::Parse (std::unique_ptr<Base> *return_token, Nonterminal::Name nonterminal_to_parse)
{

#line 60 "../using_unique_ptr_parser.trison"


#line 87 "../using_unique_ptr_parser.cpp"

    return Parse_(return_token, nonterminal_to_parse);
}

// ///////////////////////////////////////////////////////////////////////
// begin internal trison-generated parser guts -- don't use
// ///////////////////////////////////////////////////////////////////////

void Parser::PrintIndented_ (std::ostream &stream, char const *string) const
{
    assert(string != NULL);
    stream << "Parser: " << "    ";
    while (*string != '\0')
    {
        if (*string == '\n')
            stream << '\n' << "Parser: " << "    ";
        else
            stream << *string;
        ++string;
    }
}

std::ostream &operator << (std::ostream &stream, Parser::ParserReturnCode parser_return_code)
{
    if (std::size_t(parser_return_code) < Parser::ms_parser_return_code_string_count_)
        stream << Parser::ms_parser_return_code_string_table_[std::size_t(parser_return_code)];
    else
        stream << "!INVALID!ParserReturnCode!";
    return stream;
}

std::ostream &operator << (std::ostream &stream, Parser::Token const &token)
{
    if (token.m_id < Parser::ms_token_name_count_)
        stream << Parser::ms_token_name_table_[token.m_id];
    else
        stream << "!INVALID!TOKEN!";
    return stream;
}

char const *const Parser::ms_parser_return_code_string_table_[] =
{
    "PRC_SUCCESS",
    "PRC_UNHANDLED_PARSE_ERROR",
    "PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_COUNT",
    "PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_QUEUE_SIZE",
    "PRC_EXCEEDED_MAX_ALLOWABLE_PARSE_TREE_DEPTH",
    "PRC_INTERNAL_ERROR",
};
std::size_t const Parser::ms_parser_return_code_string_count_ = sizeof(Parser::ms_parser_return_code_string_table_) / sizeof(*Parser::ms_parser_return_code_string_table_);

char const *const Parser::ms_token_name_table_[] =
{
    "'\\0'",
    "'\\x01'",
    "'\\x02'",
    "'\\x03'",
    "'\\x04'",
    "'\\x05'",
    "'\\x06'",
    "'\\a'",
    "'\\b'",
    "'\\t'",
    "'\\n'",
    "'\\v'",
    "'\\f'",
    "'\\r'",
    "'\\x0E'",
    "'\\x0F'",
    "'\\x10'",
    "'\\x11'",
    "'\\x12'",
    "'\\x13'",
    "'\\x14'",
    "'\\x15'",
    "'\\x16'",
    "'\\x17'",
    "'\\x18'",
    "'\\x19'",
    "'\\x1A'",
    "'\\x1B'",
    "'\\x1C'",
    "'\\x1D'",
    "'\\x1E'",
    "'\\x1F'",
    "' '",
    "'!'",
    "'\"'",
    "'#'",
    "'$'",
    "'%'",
    "'&'",
    "'\\''",
    "'('",
    "')'",
    "'*'",
    "'+'",
    "','",
    "'-'",
    "'.'",
    "'/'",
    "'0'",
    "'1'",
    "'2'",
    "'3'",
    "'4'",
    "'5'",
    "'6'",
    "'7'",
    "'8'",
    "'9'",
    "':'",
    "';'",
    "'<'",
    "'='",
    "'>'",
    "'?'",
    "'@'",
    "'A'",
    "'B'",
    "'C'",
    "'D'",
    "'E'",
    "'F'",
    "'G'",
    "'H'",
    "'I'",
    "'J'",
    "'K'",
    "'L'",
    "'M'",
    "'N'",
    "'O'",
    "'P'",
    "'Q'",
    "'R'",
    "'S'",
    "'T'",
    "'U'",
    "'V'",
    "'W'",
    "'X'",
    "'Y'",
    "'Z'",
    "'['",
    "'\\\\'",
    "']'",
    "'^'",
    "'_'",
    "'`'",
    "'a'",
    "'b'",
    "'c'",
    "'d'",
    "'e'",
    "'f'",
    "'g'",
    "'h'",
    "'i'",
    "'j'",
    "'k'",
    "'l'",
    "'m'",
    "'n'",
    "'o'",
    "'p'",
    "'q'",
    "'r'",
    "'s'",
    "'t'",
    "'u'",
    "'v'",
    "'w'",
    "'x'",
    "'y'",
    "'z'",
    "'{'",
    "'|'",
    "'}'",
    "'~'",
    "'\\x7F'",
    "'\\x80'",
    "'\\x81'",
    "'\\x82'",
    "'\\x83'",
    "'\\x84'",
    "'\\x85'",
    "'\\x86'",
    "'\\x87'",
    "'\\x88'",
    "'\\x89'",
    "'\\x8A'",
    "'\\x8B'",
    "'\\x8C'",
    "'\\x8D'",
    "'\\x8E'",
    "'\\x8F'",
    "'\\x90'",
    "'\\x91'",
    "'\\x92'",
    "'\\x93'",
    "'\\x94'",
    "'\\x95'",
    "'\\x96'",
    "'\\x97'",
    "'\\x98'",
    "'\\x99'",
    "'\\x9A'",
    "'\\x9B'",
    "'\\x9C'",
    "'\\x9D'",
    "'\\x9E'",
    "'\\x9F'",
    "'\\xA0'",
    "'\\xA1'",
    "'\\xA2'",
    "'\\xA3'",
    "'\\xA4'",
    "'\\xA5'",
    "'\\xA6'",
    "'\\xA7'",
    "'\\xA8'",
    "'\\xA9'",
    "'\\xAA'",
    "'\\xAB'",
    "'\\xAC'",
    "'\\xAD'",
    "'\\xAE'",
    "'\\xAF'",
    "'\\xB0'",
    "'\\xB1'",
    "'\\xB2'",
    "'\\xB3'",
    "'\\xB4'",
    "'\\xB5'",
    "'\\xB6'",
    "'\\xB7'",
    "'\\xB8'",
    "'\\xB9'",
    "'\\xBA'",
    "'\\xBB'",
    "'\\xBC'",
    "'\\xBD'",
    "'\\xBE'",
    "'\\xBF'",
    "'\\xC0'",
    "'\\xC1'",
    "'\\xC2'",
    "'\\xC3'",
    "'\\xC4'",
    "'\\xC5'",
    "'\\xC6'",
    "'\\xC7'",
    "'\\xC8'",
    "'\\xC9'",
    "'\\xCA'",
    "'\\xCB'",
    "'\\xCC'",
    "'\\xCD'",
    "'\\xCE'",
    "'\\xCF'",
    "'\\xD0'",
    "'\\xD1'",
    "'\\xD2'",
    "'\\xD3'",
    "'\\xD4'",
    "'\\xD5'",
    "'\\xD6'",
    "'\\xD7'",
    "'\\xD8'",
    "'\\xD9'",
    "'\\xDA'",
    "'\\xDB'",
    "'\\xDC'",
    "'\\xDD'",
    "'\\xDE'",
    "'\\xDF'",
    "'\\xE0'",
    "'\\xE1'",
    "'\\xE2'",
    "'\\xE3'",
    "'\\xE4'",
    "'\\xE5'",
    "'\\xE6'",
    "'\\xE7'",
    "'\\xE8'",
    "'\\xE9'",
    "'\\xEA'",
    "'\\xEB'",
    "'\\xEC'",
    "'\\xED'",
    "'\\xEE'",
    "'\\xEF'",
    "'\\xF0'",
    "'\\xF1'",
    "'\\xF2'",
    "'\\xF3'",
    "'\\xF4'",
    "'\\xF5'",
    "'\\xF6'",
    "'\\xF7'",
    "'\\xF8'",
    "'\\xF9'",
    "'\\xFA'",
    "'\\xFB'",
    "'\\xFC'",
    "'\\xFD'",
    "'\\xFE'",
    "'\\xFF'",
    "END_",
    "ERROR_",
    "BAD_TOKEN",
    "LEAF",
    "root",
    "expression",
    "expression_list"
};
std::size_t const Parser::ms_token_name_count_ = sizeof(Parser::ms_token_name_table_) / sizeof(*Parser::ms_token_name_table_);

void Parser::ThrowAwayToken_ (Token &&token_) throw()
{
    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing throw-away-token actions on token " << token_ << '\n')
    ThrowAwayTokenData_(std::move(token_.m_data));
}

void Parser::ThrowAwayTokenData_ (Token::Data &&token_data) throw()
{
}

Parser::Token::Data Parser::InsertLookaheadErrorActions_ (Token const &noconsume_lookahead_token)
{
    return nullptr;
}

Parser::Token::Data Parser::DiscardLookaheadActions_ (Token &&consume_stack_top_error_token, Token &&consume_lookahead_token)
{
    ThrowAwayToken_(std::move(consume_lookahead_token));
    return std::move(consume_stack_top_error_token.m_data);
}

Parser::Token::Data Parser::PopStack1Actions_ (std::vector<Token> &consume_stack_top_tokens, Token &&consume_lookahead_token)
{
    ThrowAwayToken_(std::move(consume_stack_top_tokens[0]));
    return std::move(consume_lookahead_token.m_data);
}

Parser::Token::Data Parser::PopStack2Actions_ (std::vector<Token> &consume_stack_top_tokens, Token const &noconsume_lookahead_token)
{
    ThrowAwayToken_(std::move(consume_stack_top_tokens[1]));
    return std::move(consume_stack_top_tokens[0].m_data);
}

Parser::Token::Data Parser::RunNonassocErrorActions_ (Token const &noconsume_lookahead_token)
{
    return nullptr;
}

Parser::Token Parser::Scan_ () throw()
{
    TRISON_CPP_DEBUG_CODE_(DSF_SCANNER_ACTION, *DebugSpewStream() << "Parser: " << "Executing scan actions to retrieve next token...\n")


#line 78 "../using_unique_ptr_parser.trison"

    assert(m_scanner != nullptr);
    return m_scanner->Scan();

#line 455 "../using_unique_ptr_parser.cpp"

    TRISON_CPP_DEBUG_CODE_(DSF_PROGRAMMER_ERROR, *DebugSpewStream() << "PROGRAMMER ERROR: No value returned from scan_actions code block\n")
    assert(false && "no value returned from scan_actions code block");
}

template <typename T>
std::ostream &operator << (std::ostream &out, std::set<T> const &s)
{
    out << "{ ";
    for (typename std::set<T>::const_iterator it = s.begin(), it_end = s.end(); it != it_end; ++it)
        out << *it << ", ";
    out << '}';
    return out;
}

template <typename T>
std::ostream &operator << (std::ostream &out, std::vector<T> const &s)
{
    out << "[ ";
    for (typename std::vector<T>::const_iterator it = s.begin(), it_end = s.end(); it != it_end; ++it)
        out << *it << ", ";
    out << ']';
    return out;
}

std::uint32_t Parser::NonterminalStartStateIndex_ (Parser::Nonterminal::Name nonterminal)
{
    switch (nonterminal)
    {
        case Nonterminal::expression: return 12;
        case Nonterminal::expression_list: return 6;
        case Nonterminal::root: return 1;
        default: assert(false && "invalid nonterminal"); return 0;
    }
}

bool Parser::HasEncounteredErrorState () const
{
    return (m_realized_state_ == NULL) ? false : m_realized_state_->HasEncounteredErrorState();
}

std::int64_t Parser::MaxAllowableLookaheadCount () const
{
    return m_max_allowable_lookahead_count;
}

std::size_t Parser::MaxRealizedLookaheadCount () const
{
    return (m_realized_state_ == NULL) ? 0 : m_realized_state_->MaxRealizedLookaheadCount();
}

std::int64_t Parser::MaxAllowableLookaheadQueueSize () const
{
    return m_max_allowable_lookahead_queue_size;
}

std::size_t Parser::MaxRealizedLookaheadQueueSize () const
{
    return (m_realized_state_ == NULL) ? 0 : m_realized_state_->MaxRealizedLookaheadQueueSize();
}

std::int64_t Parser::MaxAllowableParseTreeDepth () const
{
    return m_max_allowable_parse_tree_depth;
}

std::uint32_t Parser::MaxRealizedParseTreeDepth () const
{
    return (m_hypothetical_state_ == NULL) ? 0 : m_hypothetical_state_->m_max_realized_parse_tree_depth;
}

void Parser::SetMaxAllowableLookaheadCount (std::int64_t max_allowable_lookahead_count)
{
    m_max_allowable_lookahead_count = max_allowable_lookahead_count;
}

void Parser::SetMaxAllowableLookaheadQueueSize (std::int64_t max_allowable_lookahead_queue_size)
{
    m_max_allowable_lookahead_queue_size = max_allowable_lookahead_queue_size;
}

void Parser::SetMaxAllowableParseTreeDepth (std::int64_t max_allowable_parse_tree_depth)
{
    m_max_allowable_parse_tree_depth = max_allowable_parse_tree_depth;
}

Parser::ParserReturnCode Parser::Parse_ (Token::Data *return_token, Nonterminal::Name nonterminal_to_parse)
{
    assert(return_token != NULL && "the return-token pointer must be non-NULL");

    TRISON_CPP_DEBUG_CODE_(DSF_START_END_PARSE, *DebugSpewStream() << "Parser: " << "Starting parse\n")

    ParserReturnCode parser_return_code_ = PRC_INTERNAL_ERROR;
    *return_token = nullptr;


    std::uint32_t start_state_index = NonterminalStartStateIndex_(nonterminal_to_parse);

    if (m_realized_state_ != NULL) // This happens when parsing again, not from scratch.
    {
        assert(m_hypothetical_state_ == NULL);
        // Note that this resets the error state.
        m_realized_state_->Reinitialize(start_state_index);
        // Delete this entirely to be initialized anew, since it has no state that
        // carries over between parses.
        delete m_hypothetical_state_;
        m_hypothetical_state_ = NULL;
    }
    else // This happens when parsing for the first time.
        m_realized_state_ = new RealizedState_(start_state_index);

    assert(m_realized_state_->BranchVectorStack().size() == 2);
    assert(m_realized_state_->BranchVectorStack().back().size() == 1);

    m_hypothetical_state_ = new HypotheticalState_(m_realized_state_->BranchVectorStack().back()[0]);

    TRISON_CPP_DEBUG_CODE_(DSF_STACK_AND_LOOKAHEADS,
        *DebugSpewStream() << "Parser: " << "<stack> . <lookaheads>: ";
        m_realized_state_->PrintStackAndLookaheads(*DebugSpewStream());
        *DebugSpewStream() << '\n';
    )

    bool should_return = false;
    std::size_t iteration_index = 0;
    while (!should_return)
    {
        TRISON_CPP_DEBUG_CODE_(
            DSF_ITERATION_COUNT,
            *DebugSpewStream() << "Parser: " << "\n";
            *DebugSpewStream() << "Parser: " << "---------- ITERATION " << iteration_index << " --------------\n";
            PrintParserStatus_(*DebugSpewStream());
            *DebugSpewStream() << "Parser: " << '\n';
        )

        if (m_realized_state_->HasExceededMaxAllowableLookaheadCount(m_max_allowable_lookahead_count))
        {
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << "Parser: " << "Max realized lookahead count (" << m_realized_state_->MaxRealizedLookaheadCount() << ") has exceeded max allowable lookahead token count (" << m_max_allowable_lookahead_count << "); modify this limit using the default_max_allowable_lookahead_count directive (see trison.cpp.targetspec), or using the SetMaxAllowableLookaheadCount method.  Returning with error.\n")
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_COUNT;
            break;
        }

        if (m_realized_state_->HasExceededMaxAllowableLookaheadQueueSize(m_max_allowable_lookahead_queue_size))
        {
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << "Parser: " << "Max realized lookahead queue size (" << m_realized_state_->MaxRealizedLookaheadQueueSize() << ") has exceeded max allowable lookahead queue size (" << m_max_allowable_lookahead_queue_size << "); modify this limit using the default_max_allowable_lookahead_queue_size directive (see trison.cpp.targetspec), or using the SetMaxAllowableLookaheadQueueSize method.  Returning with error.\n")
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_LOOKAHEAD_QUEUE_SIZE;
            break;
        }

        if (m_hypothetical_state_->HasExceededMaxAllowableParseTreeDepth(m_max_allowable_parse_tree_depth))
        {
            TRISON_CPP_DEBUG_CODE_(DSF_LIMIT_EXCEEDED, *DebugSpewStream() << "Parser: " << "Parse tree depth (" << m_hypothetical_state_->ParseTreeDepth() << ") has exceeded max allowable parse tree depth (" << m_max_allowable_parse_tree_depth << "); modify this limit using the default_max_allowable_parse_tree_depth directive (see trison.cpp.targetspec), or using the SetMaxAllowableParseTreeDepth method.  Returning with error.\n")
            parser_return_code_ = PRC_EXCEEDED_MAX_ALLOWABLE_PARSE_TREE_DEPTH;
            break;
        }

        if (m_hypothetical_state_->m_root->HasTrunkChild())
            ExecuteAndRemoveTrunkActions_(should_return, parser_return_code_, return_token);
        else
            ContinueNPDAParse_(should_return);

        TRISON_CPP_DEBUG_CODE_(DSF_ITERATION_COUNT, *DebugSpewStream() << "Parser: " << '\n')
        ++iteration_index;
    }

    TRISON_CPP_DEBUG_CODE_(
        DSF_ITERATION_COUNT,
        *DebugSpewStream() << "Parser: " << "\n";
        *DebugSpewStream() << "Parser: " << "---------- RETURNING --------------\n";
        PrintParserStatus_(*DebugSpewStream());
        *DebugSpewStream() << "Parser: " << '\n';
    )

    assert(std::size_t(parser_return_code_) < ms_parser_return_code_string_count_ && "this should never happen");
    TRISON_CPP_DEBUG_CODE_(
        DSF_START_END_PARSE,
        *DebugSpewStream() << "Parser: " << "Parse() is returning " << ms_parser_return_code_string_table_[parser_return_code_] << '\n';
    )

    return parser_return_code_;
}

void Parser::ExecuteAndRemoveTrunkActions_ (bool &should_return, ParserReturnCode &parser_return_code_, Token::Data *&return_token)
{
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << "Parse stack tree has trunk; executing trunk actions.\n")
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << '\n')

    if (m_hypothetical_state_->m_root->HasTrunkChild())
    {
        // The trunk_child is popped and then will die by the end of this function.
        // Using std::unique_ptr for exception safety -- if an exception is thrown within
        // this function, then trunk_child still needs to be deleted.
        std::unique_ptr<ParseTreeNode_> trunk_child(m_hypothetical_state_->m_root->PopTrunkChild());
        assert(trunk_child->m_parent_node == NULL);
        assert(trunk_child->m_child_nodes.empty());

        bool destroy_and_recreate_parse_tree = false;

        switch (trunk_child->m_spec.m_type)
        {
            case ParseTreeNode_::RETURN: {
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action RETURN.\n")
                assert(m_realized_state_->TokenStack().size() == 3);
                parser_return_code_ = PRC_SUCCESS;
                // This doesn't change the structure of the stack but does take ownership of the top stack token.
                // This must be done so that the return token isn't destroyed with the parser.
                m_realized_state_->StealTokenStackTop(return_token);
                should_return = true;
                break;
            }
            case ParseTreeNode_::ABORT: {
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action ABORT.\n")
                assert(m_realized_state_->TokenStack().size() == 1);
                parser_return_code_ = PRC_UNHANDLED_PARSE_ERROR;
                should_return = true;
                break;
            }
            case ParseTreeNode_::REDUCE: {
                // Execute the appropriate rule on the top tokens in the stack
                std::uint32_t const &rule_index = trunk_child->m_spec.m_single_data;
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action REDUCE rule " << rule_index << "; " << Grammar_::ms_rule_table_[rule_index].m_description << '\n')
                Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[rule_index];
                Token const *lookahead = NULL;
                if (rule.m_has_lookahead_directive)
                {
                    assert(!m_realized_state_->LookaheadQueue().empty());
                    lookahead = &m_realized_state_->LookaheadQueue().front();
                }
                Token::Data reduced_nonterminal_token_data = ExecuteReductionRule_(rule_index, m_realized_state_->TokenStack(), lookahead);
                m_realized_state_->ExecuteActionReduce(rule, std::move(reduced_nonterminal_token_data), m_hypothetical_state_->m_hps_queue);
                // This is done essentially so that m_realized_lookahead_cursor can be reset.
                destroy_and_recreate_parse_tree = true;
                break;
            }
            case ParseTreeNode_::SHIFT: {
                std::uint32_t const &shifted_token_id = trunk_child->m_spec.m_single_data;
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action SHIFT " << Token(shifted_token_id) << '\n')
                m_realized_state_->ExecuteActionShift(trunk_child->m_child_branch_vector, m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::INSERT_LOOKAHEAD_ERROR: {
                // INSERT_LOOKAHEAD_ERROR -- this should have access to the lookahead that
                // caused the error to be generated, and it should return a token that will
                // be used as the %error token.
                //
                // Start:  <realized-stack-tokens> . <lookahead>
                //                                 ^~~~~~~~~~^
                //                                 input to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <lookahead>
                //                                   ^~~~~~~^
                //                                   output from handler code

                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action INSERT_LOOKAHEAD_ERROR, and setting has-encountered-error-state flag.\n")
                Token const &lookahead = Lookahead_(0);
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO 2 lookahead retrieved from Lookahead_(0) for INSERT_LOOKAHEAD_ERROR action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                {   // This code block is just to limit the scope of resulting_error_token
                    Token resulting_error_token(Terminal::ERROR_, InsertLookaheadErrorActions_(lookahead));
                    m_realized_state_->PushFrontLookahead(std::move(resulting_error_token), m_hypothetical_state_->m_hps_queue);
                }
                m_realized_state_->SetHasEncounteredErrorState();
                //m_realized_state_->ExecuteActionInsertLookaheadError(m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::DISCARD_LOOKAHEAD: {
                // DISCARD_LOOKAHEAD -- this can only happen if the top of the realized stack
                // is %error; it should have access to the %error token and the lookahead
                // token, and it should return a token that will be used as the resulting
                // %error token (e.g. combining the file locations of the two input tokens).
                //
                // Start:  <realized-stack-tokens> <%error> . <lookahead0> <rest-of-lookaheads>
                //                                 ^~~~~~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> <%error> . <rest-of-lookaheads>
                //                                 ^~~~~~~^
                //                                 output from handler code (old stack top is replaced)

                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action DISCARD_LOOKAHEAD.\n")
                assert(m_realized_state_->TokenStack().back().m_id == Terminal::ERROR_);
                Token lookahead(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue));
                Token resulting_error_token = Token(Terminal::ERROR_, DiscardLookaheadActions_(std::move(m_realized_state_->TokenStack().back()), std::move(lookahead)));
                m_realized_state_->ReplaceTokenStackTopWith(std::move(resulting_error_token));
                //m_realized_state_->ExecuteActionDiscardLookahead(m_hypothetical_state_->m_hps_queue);
                break;
            }
            case ParseTreeNode_::POP_STACK: {
                // POP_STACK 1 -- this can only happen when the lookahead is %error (and in
                // this case, the top of the realized stack is not %error); it should have
                // access to the token about to be popped and the lookahead %error token, and
                // it should return a token that will be used as the resulting %error token
                // (e.g. combining the file locations of the two input tokens).
                //
                // Start:  <realized-stack-tokens> <token0> . <%error> <rest-of-lookaheads>
                //                                 ^~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <rest-of-lookaheads>
                //                                   ^~~~~~~^
                //                                   output from handler code
                //
                // POP_STACK 2 -- this can only happen when the lookahead is %end; it should
                // have access to the 2 tokens about to be popped and the lookahead %end token,
                // and it should return a token that will be used as the resulting %error token
                // (e.g. combining the file locations of the three input tokens).
                //
                // Start:  <realized-stack-tokens> <token1> <token0> . <%end>
                //                                 ^~~~~~~~~~~~~~~~~~~~~~~~~^
                //                                 inputs to handler code
                //
                // Result: <realized-stack-tokens> . <%error> <%end>
                //                                   ^~~~~~~^
                //                                   output from handler code
                //
                // NOTE: The semantics for POP_STACK 1 and POP_STACK 2 are different; the handler
                // code is expected to consume (e.g. delete, aggregate, etc) all inputs for
                // POP_STACK 1, and is expected to only consume the popped stack tokens for
                // POP_STACK 2 (and only read from the lookahead).

                std::uint32_t const &pop_count = trunk_child->m_spec.m_single_data;
                TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "Executing trunk action POP_STACK " << pop_count << ".\n")
                assert(pop_count == 1 || pop_count == 2);
                assert(m_realized_state_->TokenStack().size() > pop_count);

                if (pop_count == 1)
                {
                    std::vector<Token> popped_tokens;
                    popped_tokens.emplace_back(m_realized_state_->PopStack());
                    assert(popped_tokens.size() == pop_count);
                    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')

                    Token lookahead(std::move(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue)));
                    TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "lookahead for POP_STACK " << pop_count << " action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                    assert(lookahead.m_id == Terminal::ERROR_);
                    {   // This code block is just to limit the scope of resulting_error_token
                        Token resulting_error_token(Terminal::ERROR_, PopStack1Actions_(popped_tokens, std::move(lookahead)));
                        m_realized_state_->PushFrontLookahead(std::move(resulting_error_token), m_hypothetical_state_->m_hps_queue);
                    }
                }
                else
                {
                    assert(pop_count == 2);

                    if (false)
                    {
                        // plain ol' pop stack 2 times -- this is the old behavior

                        //std::vector<Token> popped_tokens(pop_count, Token(Nonterminal::none_));
                        std::vector<Token> popped_tokens;
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens[1] = std::move(m_realized_state_->PopStack());
                        popped_tokens[0] = std::move(m_realized_state_->PopStack());
                        assert(popped_tokens.size() == pop_count);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')

                        Token const &lookahead = Lookahead_(0);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "lookahead for POP_STACK " << pop_count << " action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                        PopStack2Actions_(popped_tokens, lookahead);
                    }
                    else if (true)
                    {
                        // pop stack 2 times, then push the result onto the front of the lookahead queue.

                        //std::vector<Token> popped_tokens(pop_count, Token(Nonterminal::none_));
                        std::vector<Token> popped_tokens;
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens[1] = std::move(m_realized_state_->PopStack());
                        popped_tokens[0] = std::move(m_realized_state_->PopStack());
                        assert(popped_tokens.size() == pop_count);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')

                        Token const &lookahead = Lookahead_(0);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "lookahead for POP_STACK " << pop_count << " action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                        {   // This code block is just to limit the scope of resulting_error_token
                            Token resulting_error_token(Terminal::ERROR_, PopStack2Actions_(popped_tokens, lookahead));
                            m_realized_state_->PushFrontLookahead(std::move(resulting_error_token), m_hypothetical_state_->m_hps_queue);
                        }
                    }
                    else if (false)
                    {
                        // pop stack 2 times and push resulting error token onto stack -- this is new behavior

                        //std::vector<Token> popped_tokens(pop_count, Token(Nonterminal::none_));
                        std::vector<Token> popped_tokens;
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens[1] = std::move(m_realized_state_->PopStack());
                        popped_tokens[0] = std::move(m_realized_state_->TokenStack().back()); // Don't pop this one; will replace.
                        assert(popped_tokens.size() == pop_count);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')

                        Token const &lookahead = Lookahead_(0);
                        //assert(lookahead.m_id == Terminal::END_);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "lookahead for POP_STACK " << pop_count << " action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                        Token resulting_error_token(Terminal::ERROR_, PopStack2Actions_(popped_tokens, lookahead));
                        m_realized_state_->ReplaceTokenStackTopWith(std::move(resulting_error_token));
                    }
                    else
                    {
                        // TEMP: pop 3 times

                        // pop stack 2 times and push resulting error token onto stack -- this is new behavior

                        std::uint32_t pop_count = 3; // shadowing earlier one
                        assert(m_realized_state_->TokenStack().size() >= pop_count);

                        //std::vector<Token> popped_tokens(pop_count, Token(Nonterminal::none_));
                        std::vector<Token> popped_tokens;
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens.emplace_back(Token(Nonterminal::none_));
                        popped_tokens[2] = std::move(m_realized_state_->PopStack());
                        popped_tokens[1] = std::move(m_realized_state_->PopStack());
                        popped_tokens[0] = std::move(m_realized_state_->TokenStack().back()); // Don't pop this one; will replace.
                        assert(popped_tokens.size() == pop_count);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "HIPPO lookahead for POP_STACK action is " << ms_token_name_table_[Lookahead_(0).m_id] << '\n')

                        Token const &lookahead = Lookahead_(0);
                        //assert(lookahead.m_id == Terminal::END_);
                        TRISON_CPP_DEBUG_CODE_(DSF_PARSER_ACTION, *DebugSpewStream() << "Parser: " << "lookahead for POP_STACK " << pop_count << " action is " << ms_token_name_table_[lookahead.m_id] << '\n')
                        Token resulting_error_token(Terminal::ERROR_, PopStack2Actions_(popped_tokens, lookahead));
                        m_realized_state_->ReplaceTokenStackTopWith(std::move(resulting_error_token));
                    }
                }

                // Because POP_STACK involves popping the stack, the parse tree should be destroyed and
                // recreated (from the branches in the top of the realized state stack).  This is somewhat
                // draconian and non-optimal, but simple and effective.
                destroy_and_recreate_parse_tree = true;
                // TODO: Because HPS branches are blocked right after POP_STACK, maybe don't bother adding any
                // additional children below POP_STACK nodes (i.e. one HPS child of POP_STACK is sufficient to
                // keep it alive probably).  This would reduce the number of memory operations.
                break;
            }

            default:
                assert(false && "this should not happen");
                break;
        }

        TRISON_CPP_DEBUG_CODE_(DSF_STACK_AND_LOOKAHEADS,
            *DebugSpewStream() << "Parser: " << "<stack> . <lookaheads>: ";
            m_realized_state_->PrintStackAndLookaheads(*DebugSpewStream());
            *DebugSpewStream() << '\n';
        )

        if (destroy_and_recreate_parse_tree)
        {
            TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << "    Destroying and recreating parse tree based on top of branch stack of of realized state.\n")
            m_hypothetical_state_->DestroyParseTree();
            CreateParseTreeFromRealizedState_();
        }
    }
}

void Parser::ContinueNPDAParse_ (bool &should_return)
{
    // If there are no non-blocked hps-es, then the parse should stop.  If any non-blocked hps-es
    // are processed, then this flag will be set to false.
    should_return = true;

    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << "Parse stack tree does not have trunk; continuing parse.\n")

    // If there's a SHIFT/REDUCE conflict, then see if it can be resolved first.
    {
        ParseTreeNode_ *shift  = NULL;
        ParseTreeNode_ *reduce = NULL;
        // TODO: Move this handling into its own function
        // NOTE: This only works at the root.  If that were to change, then various things
        // would need to scan over only the HPSes that are contained within the relevant subtree.
        bool has_shift_reduce_conflict = m_hypothetical_state_->m_root->HasShiftReduceConflict(shift, reduce);
        bool has_shift_reduce_conflict_and_should_resolve = false;
        if (has_shift_reduce_conflict)
        {
            // Should not do anything unless the shift and reduce branches have the same
            // m_realized_lookahead_cursor (e.g. a REDUCE action will start out with
            // m_realized_lookahead_cursor == 0, while a SHIFT action will start out with
            // m_realized_lookahead_cursor == 1, but the REDUCE action branch needs to be
            // allowed to catch up before having any chance at the SHIFT/REDUCE conflict
            // being resolvable).
            if (m_hypothetical_state_->MinAndMaxRealizedLookaheadCursorsAreEqual())
                has_shift_reduce_conflict_and_should_resolve = true;
            else
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "    SHIFT/REDUCE conflict encountered, but the min and max realized lookahead cursors for all HPSes are not equal, so it's not ready for the conflict to be resolved.\n")
            }
        }

        if (has_shift_reduce_conflict_and_should_resolve)
        {
            assert(shift != NULL);
            assert(reduce != NULL);
            ParseTreeNode_::PrecedenceIndexRange shift_precedence_index_range = shift->ComputePrecedenceIndexRange(1);
            ParseTreeNode_::PrecedenceIndexRange reduce_precedence_index_range = reduce->ComputePrecedenceIndexRange(1);
            assert(reduce_precedence_index_range.first == reduce_precedence_index_range.second);

            TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "    SHIFT/REDUCE conflict encountered. REDUCE precedence level range: [" << Grammar_::ms_precedence_table_[reduce_precedence_index_range.first].m_name << ", " << Grammar_::ms_precedence_table_[reduce_precedence_index_range.second].m_name << "], SHIFT precedence level range: [" << Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_name << ", " << Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_name << "]\n")

            // 6 possibilities (the higher lines indicate higher precedence level.  same line
            // indicates equality).  there is always exactly one reduce hps, and at least
            // one shift hps.
            //
            // note that if a shift and a reduce have the same precedence level, then they also
            // have the same associativity.
            //
            // 1.     shift        2.     shift        3.
            //        shift               shift
            // reduce              reduce shift        reduce shift
            //
            // 4.                  5.                  6.
            //                                                shift
            // reduce shift        reduce              reduce shift
            //        shift               shift               shift
            //        shift               shift
            //
            // cases 1 and 5 can be trivially resolved -- by pruning the reduce
            // and by pruning the shift respectively.
            //
            // case 2 can only be resolved if the associativity of the reduction rule
            // is RIGHT, in which case the reduce is pruned.  otherwise no resolution
            // can be reached at this point.
            //
            // case 3 may be trivially resolved via rule associativity (LEFT causes the
            // shift to be pruned, RIGHT causes the reduce to be pruned, and NONASSOC
            // should cause an error).
            //
            // case 4 can only be resolved if the associativity of the reduction rule
            // is LEFT, in which case the shift is pruned.  otherwise no resolution
            // can be reached at this point.
            //
            // case 6 can not be resolved at this point.

            bool conflict_resolved = false;

            // Case 1
            if (Grammar_::ms_precedence_table_[reduce_precedence_index_range.second].m_level < Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level)
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 1; REDUCE < SHIFT; pruning REDUCE and continuing.\n")
                // TODO: Use std::unique_ptr and pass in via move so that the `reduce = NULL` is unnecessary.
                m_hypothetical_state_->DeleteBranch(reduce);
                reduce = NULL;
                conflict_resolved = true;
            }
            // Case 2
            else if (Grammar_::ms_precedence_table_[reduce_precedence_index_range.first].m_level == Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level &&
                     Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level < Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level)
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 2; REDUCE <= SHIFT;\n")
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
                if (reduction_rule_precedence.m_associativity == Grammar_::ASSOC_RIGHT)
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Pruning REDUCE (because it is right-associative) and continuing.\n")
                    m_hypothetical_state_->DeleteBranch(reduce);
                    reduce = NULL;
                    conflict_resolved = true;
                }
                else
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Can't resolve conflict at this time.\n")
                }
            }
            // Case 3
            else if (Grammar_::ms_precedence_table_[reduce_precedence_index_range.second].m_level == Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level &&
                     Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level == Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level)
            {
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 3; REDUCE == SHIFT; rule " << reduce->m_spec.m_single_data << " associativity: " <<
 Grammar_::ms_associativity_string_table_[reduction_rule_precedence.m_associativity] << '\n')
                switch (reduction_rule_precedence.m_associativity)
                {
                    case Grammar_::ASSOC_LEFT:
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Pruning SHIFT (because REDUCE is left-associative) and continuing.\n")
                        m_hypothetical_state_->DeleteBranch(shift);
                        shift = NULL;
                        conflict_resolved = true;
                        break;

                    case Grammar_::ASSOC_NONASSOC:
                    {
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Composition of nonassoc rules with the same precedence is an error.  Pruning both SHIFT and REDUCE.  Recreating parse tree under INSERT_LOOKAHEAD_ERROR action.\n")
                        // Neither SHIFT nor REDUCE should survive.  Instead, invoke the nonassoc error actions
                        // on the lookahead, and insert an %error token using the returned Token::Data value.
                        //
                        // Start:  <realized-stack-tokens> . <lookahead>
                        //                                 ^~~~~~~~~~^
                        //                                 input to handler code
                        //
                        // Result: <realized-stack-tokens> . <%error> <lookahead>
                        //                                   ^~~~~~~^
                        //                                   output from handler code

                        {   // This code block is just to limit the scope of resulting_error_token
                            Token resulting_error_token(Terminal::ERROR_, RunNonassocErrorActions_(Lookahead_(0)));
                            m_realized_state_->PushFrontLookahead(std::move(resulting_error_token), m_hypothetical_state_->m_hps_queue);
                        }
                        m_realized_state_->SetHasEncounteredErrorState();

                        m_hypothetical_state_->DeleteBranch(shift);
                        m_hypothetical_state_->DeleteBranch(reduce);
                        // Just verify that the HPS queue has been totally nullified by the above actions.
                        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                        {
                            assert(*hps_it == NULL);
                        }
                        m_hypothetical_state_->m_hps_queue.clear();
                        assert(m_hypothetical_state_->m_new_hps_queue.empty());
                        assert(m_hypothetical_state_->m_root->m_child_nodes.empty());

                        // Create fresh HPSes at the root from the realized state.
                        CreateParseTreeFromRealizedState_();

                        // The processing later in this function (see `if (conflict_resolved)` block)
                        // is expecting the HPSes to be in m_hps_queue, and m_new_hps_queue to be empty.
                        assert(!m_hypothetical_state_->m_hps_queue.empty());
                        assert(m_hypothetical_state_->m_new_hps_queue.empty());

                        // Mark the conflict as resolved.
                        conflict_resolved = true;
                        break;
                    }

                    case Grammar_::ASSOC_RIGHT:
                        TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Pruning REDUCE (because it is right-associative) and continuing.\n")
                        m_hypothetical_state_->DeleteBranch(reduce);
                        reduce = NULL;
                        conflict_resolved = true;
                        break;

                    default:
                        assert(false && "this should never happen");
                        break;
                }
            }
            // Case 4
            else if (Grammar_::ms_precedence_table_[reduce_precedence_index_range.second].m_level == Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level &&
                     Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level < Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level)
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 4; REDUCE >= SHIFT;\n")
                Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduce->m_spec.m_single_data];
                Grammar_::Precedence_ const &reduction_rule_precedence = Grammar_::ms_precedence_table_[reduction_rule.m_precedence_index];
                if (reduction_rule_precedence.m_associativity == Grammar_::ASSOC_LEFT)
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Pruning SHIFT (because REDUCE is left-associative) and continuing.\n")
                    m_hypothetical_state_->DeleteBranch(shift);
                    shift = NULL;
                    conflict_resolved = true;
                }
                else
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Can't resolve conflict at this time.\n")
                }
            }
            // Case 5
            else if (Grammar_::ms_precedence_table_[reduce_precedence_index_range.first].m_level > Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level)
            {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 5; REDUCE > SHIFT; pruning SHIFT and continuing.\n")
                m_hypothetical_state_->DeleteBranch(shift);
                shift = NULL;
                conflict_resolved = true;
            }
            // Case 6
            else {
                TRISON_CPP_DEBUG_CODE_(DSF_SHIFT_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "        Case 6; ambiguous SHIFT/REDUCE precedence comparison; can't resolve conflict at this time.\n")
                assert(Grammar_::ms_precedence_table_[reduce_precedence_index_range.first].m_level > Grammar_::ms_precedence_table_[shift_precedence_index_range.first].m_level);
                assert(Grammar_::ms_precedence_table_[reduce_precedence_index_range.second].m_level < Grammar_::ms_precedence_table_[shift_precedence_index_range.second].m_level);
            }

            if (conflict_resolved)
            {
                should_return = false;

                assert(m_hypothetical_state_->m_new_hps_queue.empty());
                // Take new hps-es and clear old ones.
                for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
                {
                    ParseTreeNode_ *hps = *hps_it;
                    if (hps != NULL)
                        m_hypothetical_state_->m_new_hps_queue.push_back(hps);
                }
                m_hypothetical_state_->m_hps_queue.clear();
                std::swap(m_hypothetical_state_->m_hps_queue, m_hypothetical_state_->m_new_hps_queue);
                assert(m_hypothetical_state_->m_new_hps_queue.empty());
                // TODO: Break this large function up into smaller logical units
                return;
            }
        }
    }

    // Compute the minimum of all hps-es' m_realized_lookahead_cursor values, in order
    // to determine which ones have processed the lowest number of lookaheads.  This is
    // done so that one hps doesn't get way ahead of the others.
    std::uint32_t min_realized_lookahead_cursor;
    m_hypothetical_state_->ComputeMinAndMaxRealizedLookaheadCursors(&min_realized_lookahead_cursor, NULL);

    // Process transitions in order of their SortedTypeIndex.  Only process HPSes that are at min_realized_lookahead_cursor.
    assert(m_hypothetical_state_->m_new_hps_queue.empty()); // This is the starting condition
    for (std::uint32_t current_sorted_type_index = Npda_::Transition_::Order::MIN_SORTED_TYPE_INDEX; current_sorted_type_index <= Npda_::Transition_::Order::MAX_SORTED_TYPE_INDEX; ++current_sorted_type_index)
    {
        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "    Processing transitions having SortedTypeIndex equal to " << current_sorted_type_index << " and m_realized_lookahead_cursor equal to " << min_realized_lookahead_cursor << ".\n")

        if (!m_hypothetical_state_->m_new_hps_queue.empty())
        {
            TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "        Early-out based on sorted type index.\n")
            break;
        }

        // Process non-blocked hps-es.
        for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
        {
            // Skip nullified HPS nodes.
            if (*hps_it == NULL)
                continue;

            ParseTreeNode_ &hps = **hps_it;

            assert(hps.m_spec.m_type == ParseTreeNode_::HPS);
            TRISON_CPP_DEBUG_CODE_(
                DSF_TRANSITION_PROCESSING,
                *DebugSpewStream() << "Parser: " << "        Processing ";
                hps.Print(*DebugSpewStream(), this, DebugSpewPrefix(), 0, true);
            )

            // If a hps is blocked, then save it for the next parse iteration but don't do anything with it.
            if (hps.IsBlockedHPS())
            {
                TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "            Hypothetical Parser State is blocked; preserving for next iteration.\n")
                m_hypothetical_state_->m_new_hps_queue.push_back(&hps);
                *hps_it = NULL;
                continue;
            }

            // If a hps' m_realized_lookahead_cursor is greater than min_realized_lookahead_cursor, then
            // save it for the next parse iteration but don't do anything with it.
            if (hps.m_realized_lookahead_cursor > min_realized_lookahead_cursor)
            {
                TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "            Hypothetical Parser State isn't at min_realized_lookahead_cursor (which is " << min_realized_lookahead_cursor << "); preserving for next iteration.\n")
                m_hypothetical_state_->m_new_hps_queue.push_back(&hps);
                *hps_it = NULL;
                continue;
            }

            // This hps isn't blocked, so indicate that the parse should continue.
            should_return = false;

            std::uint32_t hps_state_index = hps.m_hypothetical_head.StatePtr()->Data();

            // Retrieve all transitions whose SortedTypeIndex is current_sorted_type_index.
            Npda_::TransitionVector_ const &non_epsilon_transitions = Npda_::NonEpsilonTransitionsOfState_(hps_state_index, current_sorted_type_index);
            // Exercise all valid transitions whose SortedTypeIndex is current_sorted_type_index.
            for (Npda_::TransitionVector_::const_iterator transition_it = non_epsilon_transitions.begin(), transition_it_end = non_epsilon_transitions.end(); transition_it != transition_it_end; ++transition_it)
            {
                Npda_::Transition_ const &transition = *transition_it;
                assert(transition.m_type >= Npda_::Transition_::RETURN);
                assert(transition.m_type <= Npda_::Transition_::POP_STACK);
                assert(Npda_::Transition_::Order::SortedTypeIndex(transition) == current_sorted_type_index);


                TRISON_CPP_DEBUG_CODE_(
                    DSF_TRANSITION_PROCESSING,
                    *DebugSpewStream() << "Parser: " << "            Processing transition " << ParseTreeNode_::AsString(ParseTreeNode_::Type(transition.m_type)) << " with transition token " << Token(transition.m_token_index) << " and data ";
                    if (transition.m_data_index == ParseTreeNode_::UNUSED_DATA)
                        *DebugSpewStream() << "<N/A>";
                    else
                        *DebugSpewStream() << transition.m_data_index;
                    *DebugSpewStream() << " and sorted type index " << Npda_::Transition_::Order::SortedTypeIndex(transition) << '\n';
                )


                ParseTreeNode_ *resulting_hps = NULL;
                // If it's a default transition, there's no need to access the lookahead (except in a couple of particular cases).
                if (transition.m_token_index == Nonterminal::none_)
                {
                    // Logic regarding empty reduction rules -- if this transition is REDUCE for an empty reduction rule
                    // and the lookahead is the nonterminal for that REDUCE action, then don't reduce, since that
                    // would produce an infinite loop.  There is a case where it's not necessary to access the lookahead:
                    // if this HPS is the child of a REDUCE action for the same nonterminal, then we know the lookahead
                    // is that nonterminal, so it's not necessary to check the lookahead (we don't want to access the
                    // lookahead unnecessarily).  But it's not an if-and-only-if condition; we could have just REDUCE'd
                    // that nonterminal but the HPS has no parent because the trunk action was executed and then popped,
                    // meaning that the parent of this HPS would be the parse tree root.
                    bool take_action = true;

                    assert(hps.m_parent_node != NULL);
                    if (transition.m_type == Npda_::Transition_::REDUCE)
                    {
                        Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[transition.m_data_index];
                        bool is_empty_reduction_rule = rule.m_token_count == 0;
                        bool just_reduced_this_nonterminal = hps.m_parent_node->m_spec.m_type == ParseTreeNode_::REDUCE && hps.m_parent_node->m_spec.m_single_data == rule.m_reduction_nonterminal_token_id;
                        // The fancy logical construction here is to avoid accessing the lookahead unless necessary
                        // (and technically this is not optimal, since really when executing the trunk actions,
                        // the information of "parent is REDUCE and the reduction rule nonterminal is this one"
                        // is lost in the current implementation.
                        if (is_empty_reduction_rule &&
                            (just_reduced_this_nonterminal ||
                             rule.m_reduction_nonterminal_token_id == hps.LookaheadTokenId(*this))) // lookahead is this nonterminal
                        {
                            TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "            Skipping default action REDUCE on empty reduction rule because the lookahead matches the reduction nonterminal.\n")
                            take_action = false;
                        }

                        //
                        // The following is a hacky way to check for transitions that SHOULD block a default REDUCE action.
                        // In particular, for a reduction rule ending with %lookahead[![A|B]], there will be transitions
                        //     default: REDUCE
                        //     A: INSERT_LOOKAHEAD_ERROR
                        //     B: INSERT_LOOKAHEAD_ERROR
                        // and the intent of this was for the A and B transitions to "block" the default transition, but
                        // this was not implemented correctly.  So this hack is meant to fix that bug without doing the
                        // larger refactor that would implement this correctly and robustly.
                        //

                        // Check all higher SortedTypeIndex values (higher than the SortedTypeIndex value of REDUCE) for
                        // transitions that match the lookahead -- these would block the default REDUCE action.
                        for (std::uint32_t blocking_sorted_type_index = current_sorted_type_index+1; blocking_sorted_type_index <= Npda_::Transition_::Order::MAX_SORTED_TYPE_INDEX; ++blocking_sorted_type_index)
                        {
                            Npda_::TransitionVector_ const &blocking_non_epsilon_transitions = Npda_::NonEpsilonTransitionsOfState_(hps_state_index, blocking_sorted_type_index);
                            for (Npda_::TransitionVector_::const_iterator blocking_transition_it = blocking_non_epsilon_transitions.begin(), blocking_transition_it_end = blocking_non_epsilon_transitions.end(); blocking_transition_it != blocking_transition_it_end; ++blocking_transition_it)
                            {
                                Npda_::Transition_ const &blocking_transition = *blocking_transition_it;
                                if (blocking_transition.m_token_index == hps.LookaheadTokenId(*this))
                                {
                                    // This transition is blocking the default REDUCE action, so do not take action.
                                    TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_PROCESSING, *DebugSpewStream() << "Parser: " << "            Skipping default action REDUCE because the negated lookahead directive was matched and therefore prevents it.\n")
                                    take_action = false;
                                }
                                if (!take_action)
                                    break; // No reason to keep looping.
                            }
                            if (!take_action)
                                break; // No reason to keep looping.
                        }
                    }

                    if (take_action)
                    {
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << "Parser: " << "            Exercising transition without accessing lookahead... ")
                        resulting_hps = TakeHypotheticalActionOnHPS_(hps, ParseTreeNode_::Type(transition.m_type), transition.m_data_index);
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << '\n')
                    }
                }
                // Otherwise, the lookahead must be accessed.
                else
                {
                    Token::Id lookahead_token_id = hps.LookaheadTokenId(*this);
                    if (transition.m_token_index == lookahead_token_id)
                    {
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << "Parser: " << "            Exercising transition using lookahead " << Token(lookahead_token_id) << " ... ")
                        resulting_hps = TakeHypotheticalActionOnHPS_(hps, ParseTreeNode_::Type(transition.m_type), transition.m_data_index);
                        TRISON_CPP_DEBUG_CODE_(DSF_TRANSITION_EXERCISING, *DebugSpewStream() << '\n')
                    }
                }
                if (resulting_hps != NULL)
                    m_hypothetical_state_->m_new_hps_queue.push_back(resulting_hps);
            }
        }
    }

    // Take new hps-es and clear old ones.
    assert(!m_hypothetical_state_->m_new_hps_queue.empty());
    TRISON_CPP_DEBUG_CODE_(DSF_HPS_REMOVE_DEFUNCT, *DebugSpewStream() << "Parser: " << "    Removing defunct HPSes...\n")
    for (HPSQueue_::iterator hps_it = m_hypothetical_state_->m_hps_queue.begin(), hps_it_end = m_hypothetical_state_->m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ *hps = *hps_it;
        if (hps != NULL)
        {
            TRISON_CPP_DEBUG_CODE_(
                DSF_HPS_REMOVE_DEFUNCT,
                hps->Print(*DebugSpewStream(), this, DebugSpewPrefix(), 2);
            )
            m_hypothetical_state_->DeleteBranch(hps);
        }
    }
    m_hypothetical_state_->m_hps_queue.clear();
    std::swap(m_hypothetical_state_->m_hps_queue, m_hypothetical_state_->m_new_hps_queue);
    assert(m_hypothetical_state_->m_new_hps_queue.empty());
}

Parser::Token::Data Parser::ExecuteReductionRule_ (std::uint32_t const rule_index_, TokenStack_ &token_stack_, Token const *lookahead_) throw()
{
    assert(rule_index_ < Grammar_::ms_rule_count_);
    switch (rule_index_)
    {
        default:
            assert(false && "this should never happen");
            return nullptr;

        case 0:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack_.size());
            std::unique_ptr<Tree> le(static_move_cast<std::unique_ptr<Tree>>(std::move(token_stack_[token_stack_.size()-2].m_data)));

#line 102 "../using_unique_ptr_parser.trison"

        return le;
    
#line 1354 "../using_unique_ptr_parser.cpp"
            break;
        }

        case 1:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack_.size());
            std::unique_ptr<Base> leaf(std::move(token_stack_[token_stack_.size()-1].m_data));

#line 110 "../using_unique_ptr_parser.trison"

        return leaf;
    
#line 1367 "../using_unique_ptr_parser.cpp"
            break;
        }

        case 2:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack_.size());
            std::unique_ptr<Tree> el(static_move_cast<std::unique_ptr<Tree>>(std::move(token_stack_[token_stack_.size()-2].m_data)));

#line 115 "../using_unique_ptr_parser.trison"

        return el;
    
#line 1380 "../using_unique_ptr_parser.cpp"
            break;
        }

        case 3:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack_.size());
            std::unique_ptr<Tree> el(static_move_cast<std::unique_ptr<Tree>>(std::move(token_stack_[token_stack_.size()-2].m_data)));
            std::unique_ptr<Base> e(std::move(token_stack_[token_stack_.size()-1].m_data));

#line 123 "../using_unique_ptr_parser.trison"

        el->append(std::move(e));
        return el;
    
#line 1395 "../using_unique_ptr_parser.cpp"
            break;
        }

        case 4:
        {
            assert(Grammar_::ms_rule_table_[rule_index_].m_token_count < token_stack_.size());

#line 129 "../using_unique_ptr_parser.trison"

        return make_tree();
    
#line 1407 "../using_unique_ptr_parser.cpp"
            break;
        }

    }

    TRISON_CPP_DEBUG_CODE_(DSF_PROGRAMMER_ERROR, *DebugSpewStream() << "PROGRAMMER ERROR: No value returned from reduction rule code block; rule " << rule_index_ << ": " << Grammar_::ms_rule_table_[rule_index_].m_description << '\n')
    assert(false && "no value returned from reduction rule code block");
    return nullptr;
}

void Parser::PrintParserStatus_ (std::ostream &out) const
{
    assert(m_hypothetical_state_->m_root != NULL);

    // TODO: Print full stack (this is quite a lot)
    out << "Parser: " << "Realized state branch node stacks are (each listed bottom to top):\n";
    for (BranchVector_::const_iterator it = m_realized_state_->BranchVectorStack().back().begin(),
                                       it_end = m_realized_state_->BranchVectorStack().back().end();
         it != it_end;
         ++it)
    {
        Branch_ const &branch = *it;
        out << "Parser: " << "    (";
        branch.StatePtr()->PrintRootToLeaf(out, IdentityTransform_<Npda_::StateIndex_>);
        out << ")\n";
    }

    out << "Parser: " << "Max realized lookahead count (so far) is:\n";
    out << "Parser: " << "    " << m_realized_state_->MaxRealizedLookaheadCount();
    if (m_max_allowable_lookahead_count >= 0)
        out << " (max allowable lookahead count is " << m_max_allowable_lookahead_count << ")\n";
    else
        out << " (allowable lookahead count is unlimited)\n";
    out << "Parser: " << "Max realized lookahead queue size (so far) is:\n";
    out << "Parser: " << "    " << m_realized_state_->MaxRealizedLookaheadQueueSize();
    if (m_max_allowable_lookahead_queue_size >= 0)
        out << " (max allowable lookahead queue size is " << m_max_allowable_lookahead_queue_size << ")\n";
    else
        out << " (allowable lookahead queue size is unlimited)\n";
    out << "Parser: " << "Max realized parse tree depth (so far) is:\n";
    out << "Parser: " << "    " << m_hypothetical_state_->MaxRealizedParseTreeDepth();
    if (m_max_allowable_parse_tree_depth >= 0)
        out << " (max allowable parse tree depth is " << m_max_allowable_parse_tree_depth << ")\n";
    else
        out << " (allowable parse tree depth is unlimited)\n";
    out << "Parser: " << "Has-encountered-error-state (so far) is:\n";
    out << "Parser: " << "    " << (m_realized_state_->HasEncounteredErrorState() ? "true" : "false") << '\n';
    out << "Parser: " << "Realized stack tokens then . delimiter then realized lookahead queue is:\n";
    out << "Parser: " << "    ";
    for (TokenStack_::const_iterator it = m_realized_state_->TokenStack().begin(),
                                     it_end = m_realized_state_->TokenStack().end();
         it != it_end;
         ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << ". ";
    for (TokenQueue_::const_iterator it = m_realized_state_->LookaheadQueue().begin(),
                                     it_end = m_realized_state_->LookaheadQueue().end();
         it != it_end;
         ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << '\n';
    out << "Parser: " << '\n';

    out << "Parser: " << "Parse tree (hypothetical parser states); Notation legend: <real-stack> <hyp-stack> . <hyp-lookaheads> , <real-lookaheads>\n";
    m_hypothetical_state_->m_root->Print(out, this, DebugSpewPrefix());
    out << "Parser: " << '\n';

    out << "Parser: " << "HPS queue:\n";
    for (HPSQueue_::const_iterator it = m_hypothetical_state_->m_hps_queue.begin(), it_end = m_hypothetical_state_->m_hps_queue.end(); it != it_end; ++it)
    {
        ParseTreeNode_ *hps = *it;
        //assert(hps != NULL);
        if (hps != NULL)
            hps->Print(out, this, DebugSpewPrefix(), 1);
    }
}

// ////////////////////////////////////////////////////////////////////////////
// Parser::RealizedState_
// ////////////////////////////////////////////////////////////////////////////

Parser::RealizedState_::RealizedState_ (Npda_::StateIndex_ initial_state)
    :   m_max_realized_lookahead_count(0)
    ,   m_max_realized_lookahead_queue_size(0)
    ,   m_has_encountered_error_state(false)
{
    Initialize(initial_state);
}

void Parser::RealizedState_::PushBackLookahead (Token &&lookahead, HPSQueue_ const &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    m_lookahead_queue.emplace_back(std::move(lookahead));
    UpdateMaxRealizedLookaheadCount();
}

Parser::Token Parser::RealizedState_::PopStack ()
{
    assert(!m_token_stack.empty());

    Token popped_token(std::move(m_token_stack.back()));
    m_token_stack.pop_back();

    assert(!m_branch_vector_stack.empty());
    m_branch_vector_stack.pop_back();

    assert(m_branch_vector_stack.size() == m_token_stack.size());

    return popped_token;
}

void Parser::RealizedState_::ReplaceTokenStackTopWith (Token &&replacement)
{
    assert(!m_token_stack.empty());
//    m_token_stack.back() = replacement;
    m_token_stack.pop_back();
    m_token_stack.emplace_back(std::move(replacement));
}

Parser::Token Parser::RealizedState_::PopFrontLookahead (HPSQueue_ &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    assert(!m_lookahead_queue.empty());
    // Because the contents of m_lookahead_queue are changing, and each hps's
    // m_realized_lookahead_cursor is an index into that queue, each must be updated.
    for (HPSQueue_::iterator hps_it = hps_queue.begin(), hps_it_end = hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ &hps = **hps_it;
        if (hps.m_realized_lookahead_cursor > 0)
            --hps.m_realized_lookahead_cursor;
    }
    Token retval(std::move(m_lookahead_queue.front()));
    m_lookahead_queue.pop_front();
    return retval;
}

void Parser::RealizedState_::StealTokenStackTop (Token::Data *&return_token)
{
    assert(return_token != NULL);
    assert(!m_token_stack.empty());
    *return_token = std::move(m_token_stack.back().m_data);
    // Assign the token default so that the actual return token isn't destroyed when the parser is destroyed.
    m_token_stack.back().m_data = nullptr;
}

// void Parser::RealizedState_::ExecuteAction (Npda_::Transition_::Type action, ActionData_ action_data)
// {
// }

void Parser::RealizedState_::ExecuteActionReduce (Grammar_::Rule_ const &rule, Token::Data &&reduced_nonterminal_token_data, HPSQueue_ &hps_queue)
{
    for (std::uint32_t i = 0; i < rule.m_token_count; ++i)
        PopStack();
    // Push the reduced nonterminal token data onto the front of the lookahead queue
    PushFrontLookahead(Token(rule.m_reduction_nonterminal_token_id, std::move(reduced_nonterminal_token_data)), hps_queue);
}

void Parser::RealizedState_::ExecuteActionShift (BranchVector_ const &shifted_branch_vector, HPSQueue_ &hps_queue)
{
    // Ensure that each of the branch nodes in the shifted vector are actually children of
    // the current set of branch nodes.
    assert(!m_branch_vector_stack.empty());
    // Ensure that the stack is actually consistent with regard to the parent/child relationships.
    for (BranchVector_::const_iterator it = shifted_branch_vector.begin(), it_end = shifted_branch_vector.end(); it != it_end; ++it)
    {
        // Note that m_branch_vector_stack.back() is the top of the branch vector stack.
        assert(std::any_of(m_branch_vector_stack.back().begin(), m_branch_vector_stack.back().end(), [it](Branch_ const &stack_top_branch){ return stack_top_branch == it->Parent(); }));
    }
    // Ensure that there's actually a lookahead.
    assert(!m_lookahead_queue.empty());

    // Push onto the branch node stack.
    m_branch_vector_stack.push_back(shifted_branch_vector);
    // Pop the shifted lookahead from the queue and push it onto the stack.
    m_token_stack.emplace_back(PopFrontLookahead(hps_queue));
}

void Parser::RealizedState_::ExecuteActionInsertLookaheadError (HPSQueue_ &hps_queue)
{
    PushFrontLookahead(Token(Terminal::ERROR_), hps_queue);
    SetHasEncounteredErrorState();
}

void Parser::RealizedState_::ExecuteActionDiscardLookahead (HPSQueue_ &hps_queue)
{
    assert(!m_lookahead_queue.empty());
    PopFrontLookahead(hps_queue);
}

void Parser::RealizedState_::PrintStackAndLookaheads (std::ostream &out) const
{
    for (TokenStack_::const_iterator it = TokenStack().begin(), it_end = TokenStack().end(); it != it_end; ++it)
    {
        Token const &token = *it;
        out << token << ' ';
    }
    out << '.';
    for (TokenQueue_::const_iterator it = LookaheadQueue().begin(), it_end = LookaheadQueue().end(); it != it_end; ++it)
    {
        Token const &token = *it;
        out << ' ' << token;
    }
}

void Parser::RealizedState_::ClearStack ()
{
    m_branch_vector_stack.clear();
    m_token_stack.clear();
}

void Parser::RealizedState_::Reinitialize (Npda_::StateIndex_ initial_state)
{
    // Clear the stack(s) and reset the error state.
    ClearStack();
    m_has_encountered_error_state = false;
    // But preserve m_lookahead_queue, m_max_realized_lookahead_count, and m_max_realized_lookahead_queue_size

    Initialize(initial_state);
}

void Parser::RealizedState_::Initialize (Npda_::StateIndex_ initial_state)
{
    assert(m_branch_vector_stack.empty());
    assert(m_token_stack.empty());

    BranchVector_ fallback_branch_vector;
    // State 0 is the fallback state which always results in action ABORT.
    BranchStatePtr_ fallback_state_ptr = BranchState_::CreateOrphan(0);
    // The Nonterminal::none_ is just a dummy Token::Id to go along with fallback_state_ptr.
    BranchTokenIdPtr_ fallback_token_id_ptr = BranchTokenId_::CreateOrphan(Nonterminal::none_);
    fallback_branch_vector.emplace_back(Branch_(fallback_state_ptr, fallback_token_id_ptr));
    // TODO: This probably should be emplace_back
    m_branch_vector_stack.push_back(fallback_branch_vector);

    // Put a dummy token in to correspond with the fallback state.
    m_token_stack.push_back(Token(Nonterminal::none_));

    assert(m_branch_vector_stack.size() == m_token_stack.size());

    BranchVector_ initial_branch_vector;
    // The Nonterminal::none_ is just a dummy Token::Id to go along with initial_state.
    initial_branch_vector.emplace_back(Branch_(BranchState_::CreateWithParent(fallback_state_ptr, initial_state), BranchTokenId_::CreateWithParent(fallback_token_id_ptr, Nonterminal::none_)));
    // TODO: This probably should be emplace_back
    m_branch_vector_stack.push_back(initial_branch_vector);

    // Put a dummy token in to correspond with the start state.
    m_token_stack.push_back(Token(Nonterminal::none_));

    assert(m_branch_vector_stack.size() == m_token_stack.size());

    // Ensure the parent/child relationships actually hold within m_branch_vector_stack.
    assert(m_branch_vector_stack.size() == 2);
    // Ensure that the stack is actually consistent with regard to the parent/child relationships.
    for (BranchVector_::const_iterator it = m_branch_vector_stack[1].begin(), it_end = m_branch_vector_stack[1].end(); it != it_end; ++it)
    {
        assert(std::any_of(m_branch_vector_stack[0].begin(), m_branch_vector_stack[0].end(), [it](Branch_ const &branch){ return branch == it->Parent(); }));
    }
}

void Parser::RealizedState_::PushFrontLookahead (Token &&lookahead, HPSQueue_ &hps_queue)
{
    // NOTE: For now, during this RealizedState_ and HypotheticalState_ refactor,
    // this RealizedState_ method will be responsible for handling some HypotheticalState_
    // logic (regarding the lookahead cursors of the HPS queue).  But perhaps this should
    // be factored out.

    m_lookahead_queue.emplace_front(std::move(lookahead));
    // Because the contents of m_lookahead_queue_ are changing, and each hps's
    // m_realized_lookahead_cursor is an index into that queue, each must be updated.
    for (HPSQueue_::iterator hps_it = hps_queue.begin(), hps_it_end = hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        ParseTreeNode_ &hps = **hps_it;
        ++hps.m_realized_lookahead_cursor;
    }
    UpdateMaxRealizedLookaheadCount();
}

void Parser::RealizedState_::UpdateMaxRealizedLookaheadCount ()
{
    // Subtract the number of parser-generated tokens from the length of m_lookahead_queue.
    std::size_t parser_generated_token_count = 0;
    for ( ; parser_generated_token_count < m_lookahead_queue.size(); ++parser_generated_token_count)
    {
        Token const &lookahead = m_lookahead_queue[parser_generated_token_count];
        if (IsScannerGeneratedTokenId(lookahead.m_id))
            break;
    }
    m_max_realized_lookahead_count = std::max(m_max_realized_lookahead_count, m_lookahead_queue.size() - parser_generated_token_count);

    m_max_realized_lookahead_queue_size = std::max(m_max_realized_lookahead_queue_size, m_lookahead_queue.size());
}

// ////////////////////////////////////////////////////////////////////////////
// Parser::HypotheticalState_
// ////////////////////////////////////////////////////////////////////////////

Parser::HypotheticalState_::HypotheticalState_ (Branch_ const &initial_branch)
{
    m_root = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::ROOT));

    ParseTreeNode_ *hps             = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::HPS));
    hps->m_hypothetical_head        = initial_branch;

    m_root->AddChild(hps);
    m_hps_queue.push_back(hps);
    m_max_realized_parse_tree_depth = 0;
}

Parser::HypotheticalState_::~HypotheticalState_ ()
{
    m_hps_queue.clear();
    m_new_hps_queue.clear();

    delete m_root;
    m_root = NULL;
}

bool Parser::HypotheticalState_::MinAndMaxRealizedLookaheadCursorsAreEqual () const
{
    std::uint32_t min;
    std::uint32_t max;
    ComputeMinAndMaxRealizedLookaheadCursors(&min, &max);
    return min == max;
}

bool Parser::HypotheticalState_::HasExceededMaxAllowableParseTreeDepth (std::int64_t max_allowable_parse_tree_depth) const
{
    // If the limit is negative, then excess is not possible.
    return max_allowable_parse_tree_depth >= 0 && std::int64_t(ParseTreeDepth()) > max_allowable_parse_tree_depth;
}

void Parser::HypotheticalState_::DeleteBranch (ParseTreeNode_ *branch_node)
{
    assert(!branch_node->IsRoot());

    // Find the most root-ward ancestor that is an only child that isn't the root node.
    ParseTreeNode_ *branch_root = branch_node->BranchRoot();
    assert(branch_root != NULL);
    assert(!branch_root->IsRoot());
    assert(branch_root->HasParent());

    branch_root->RemoveFromParent();
    branch_node->NullifyHPSNodeDescendantsInHPSQueue(m_hps_queue);
    delete branch_root;
}

void Parser::HypotheticalState_::DestroyParseTree ()
{
    assert(m_new_hps_queue.empty());
    // Clear all HPSes, which represent the leaf nodes of the parse tree.
    m_hps_queue.clear();
    // Delete the parse tree root, which deletes all nodes.
    delete m_root;
    // At this point, the parse tree has been destroyed.  Create a new root node.
    m_root = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::ROOT));
}

void Parser::HypotheticalState_::ComputeMinAndMaxRealizedLookaheadCursors (std::uint32_t *min, std::uint32_t *max) const
{
    if (min != NULL)
        *min = std::numeric_limits<std::uint32_t>::max();
    if (max != NULL)
        *max = std::numeric_limits<std::uint32_t>::min();

    for (HPSQueue_::const_iterator hps_it = m_hps_queue.begin(), hps_it_end = m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        // Skip nullified HPS nodes.
        if (*hps_it == NULL)
            continue;

        ParseTreeNode_ const &hps = **hps_it;
        if (min != NULL && hps.m_realized_lookahead_cursor < *min)
            *min = hps.m_realized_lookahead_cursor;
        if (max != NULL && hps.m_realized_lookahead_cursor > *max)
            *max = hps.m_realized_lookahead_cursor;
    }
}

std::uint32_t Parser::HypotheticalState_::ParseTreeDepth () const
{
    std::uint32_t parse_tree_depth = 0;

    for (HPSQueue_::const_iterator hps_it = m_hps_queue.begin(), hps_it_end = m_hps_queue.end(); hps_it != hps_it_end; ++hps_it)
    {
        // Skip nullified HPS nodes.
        if (*hps_it == NULL)
            continue;

        ParseTreeNode_ const &hps = **hps_it;
        std::uint32_t branch_depth = hps.m_depth - m_root->m_depth;
        if (branch_depth > parse_tree_depth)
            parse_tree_depth = branch_depth;
    }

    // Update m_max_realized_parse_tree_depth
    if (parse_tree_depth > m_max_realized_parse_tree_depth)
        m_max_realized_parse_tree_depth = parse_tree_depth;

    return parse_tree_depth;
}

// ////////////////////////////////////////////////////////////////////////////
// Parser::ParseTreeNode_
// ////////////////////////////////////////////////////////////////////////////

char const *Parser::ParseTreeNode_::AsString (Type type)
{
    static char const *const LOOKUP_TABLE[COUNT_] =
    {
        "ROOT",
        "RETURN",
        "ABORT",
        "REDUCE",
        "SHIFT",
        "INSERT_LOOKAHEAD_ERROR",
        "DISCARD_LOOKAHEAD",
        "POP_STACK",
        "HPS"
    };
    assert(std::uint32_t(type) < COUNT_);
    return LOOKUP_TABLE[std::uint32_t(type)];
}

bool Parser::ParseTreeNode_::ParseTreeNodeOrder::operator () (Parser::ParseTreeNode_ const *lhs, Parser::ParseTreeNode_ const *rhs) const
{
    assert(lhs != NULL);
    assert(rhs != NULL);
    assert(lhs->m_spec.m_type == rhs->m_spec.m_type); // ParseTreeNodeSet should contain only nodes of the same type.
    // for HPS, their contents must be compared.
    if (lhs->m_spec.m_type == HPS)
    {
        assert(lhs->m_child_nodes.empty());
        assert(rhs->m_child_nodes.empty());
        // hps-es are equal if their m_realized_lookahead_cursor and m_hypothetical_lookahead_token_id_queue members are.
        if (lhs->m_realized_lookahead_cursor != rhs->m_realized_lookahead_cursor)
            return lhs->m_realized_lookahead_cursor < rhs->m_realized_lookahead_cursor;
        else if (lhs->m_hypothetical_head.StatePtr() != rhs->m_hypothetical_head.StatePtr())
            return lhs->m_hypothetical_head.StatePtr() < rhs->m_hypothetical_head.StatePtr();
        else
            return std::lexicographical_compare(
                lhs->m_hypothetical_lookahead_token_id_queue.begin(), lhs->m_hypothetical_lookahead_token_id_queue.end(),
                rhs->m_hypothetical_lookahead_token_id_queue.begin(), rhs->m_hypothetical_lookahead_token_id_queue.end(),
                CompareTokenId_
            );
    }
    // For REDUCE, their contents must be compared.
    else if (lhs->m_spec.m_type == REDUCE)
    {
        // m_single_data contains the reduction rule index.
        Grammar_::Rule_ const &lhs_rule = Grammar_::ms_rule_table_[lhs->m_spec.m_single_data];
        Grammar_::Rule_ const &rhs_rule = Grammar_::ms_rule_table_[rhs->m_spec.m_single_data];
        // Sort first by rule precedence, then by rule index (lower has higher priority).
        if (Grammar_::ms_precedence_table_[lhs_rule.m_precedence_index].m_level != Grammar_::ms_precedence_table_[rhs_rule.m_precedence_index].m_level)
            return Grammar_::ms_precedence_table_[lhs_rule.m_precedence_index].m_level > Grammar_::ms_precedence_table_[rhs_rule.m_precedence_index].m_level;
        else // Sort based on rule index.
            return lhs->m_spec.m_single_data < rhs->m_spec.m_single_data;
    }
    // Otherwise just use pointer value.
    else
        return lhs < rhs;
}

Parser::ParseTreeNode_::~ParseTreeNode_ ()
{
    // TODO: figure out if stack element tokens should be thrown away
    // TODO: figure out if local lookahead queue tokens should be thrown away
    // TODO: are they actually uninitialized (default value)?
    for (ChildMap::iterator it = m_child_nodes.begin(), it_end = m_child_nodes.end(); it != it_end; ++it)
    {
        ParseTreeNodeSet &child_node_set = it->second;
        for (ParseTreeNodeSet::iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            ParseTreeNode_ *child = *child_it;
            assert(child != NULL);
            assert(child->m_parent_node == this);
            delete child;
        }
        child_node_set.clear(); // not strictly necessary, but is cleaner.
    }
}

bool Parser::ParseTreeNode_::HasTrunkChild () const
{
    if (m_spec.m_type != ROOT || m_child_nodes.size() != 1)
        return false;
    ParseTreeNodeSet const &single_type_child_node_set = m_child_nodes.begin()->second;
    if (single_type_child_node_set.size() != 1)
        return false;
    ParseTreeNode_ *single_child = *single_type_child_node_set.begin();
    assert(single_child != NULL);
    assert(single_child->m_spec.m_type != ROOT);
    return single_child->m_spec.m_type != HPS;
}

Parser::ParseTreeNode_ *Parser::ParseTreeNode_::PopTrunkChild ()
{
    assert(HasTrunkChild());
    ParseTreeNode_ *trunk_child = *m_child_nodes.begin()->second.begin();
    assert(trunk_child != NULL);
    assert(trunk_child->m_parent_node == this);
    // Reassign the children of the trunk child to this node (root).
    m_child_nodes = trunk_child->m_child_nodes;
    trunk_child->m_child_nodes.clear();
    // Set the reassigned child nodes' parent to be this node (root).
    for (ChildMap::iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
    {
        ParseTreeNodeSet &child_node_set = child_map_it->second;
        for (ParseTreeNodeSet::iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            ParseTreeNode_ *child = *child_it;
            assert(child != NULL);
            child->m_parent_node = this;
        }
    }
    trunk_child->m_parent_node = NULL;
    return trunk_child;
}

bool Parser::ParseTreeNode_::HasExactlyOneChild () const
{
    return m_child_nodes.size() == 1 && m_child_nodes.begin()->second.size() == 1;
}

Parser::ParseTreeNode_ *Parser::ParseTreeNode_::BranchRoot ()
{
    assert(!IsRoot());
    assert(HasParent());
    ParseTreeNode_ *node = this;
    while (node->HasParent() && !node->m_parent_node->IsRoot() && node->m_parent_node->HasExactlyOneChild())
    {
        node = node->m_parent_node;
        assert(node->m_spec.m_type != HPS);
    }
    return node;
}

Parser::Token::Id Parser::ParseTreeNode_::LookaheadTokenId (Parser &parser) const
{
    if (m_hypothetical_lookahead_token_id_queue.empty())
        return parser.Lookahead_(m_realized_lookahead_cursor).m_id;
    else
        return m_hypothetical_lookahead_token_id_queue.front();
}

bool Parser::ParseTreeNode_::IsBlockedHPS () const
{
    assert(m_spec.m_type == HPS);
    if (m_parent_node == NULL)
        return false;
    switch (m_parent_node->m_spec.m_type)
    {
        // Nothing can happen after returning, so this has to be blocking.
        case RETURN:
        case ABORT:
        case POP_STACK: return true;

        default:        return false;
    }
}

Parser::ParseTreeNode_::PrecedenceIndexRange Parser::ParseTreeNode_::ComputePrecedenceIndexRange (std::uint32_t current_child_depth) const
{
    if (m_spec.m_type == HPS)
    {
        // Need to look back at the rule of the (current_child_depth-1)th ancestor of this node in order
        // to get the correct rule precedence, because that's where the conflict occurred.

        assert(current_child_depth >= 2);
        // These asserts are equivalent to checking that the stack depth is at least 2.
        assert(bool(m_hypothetical_head.StatePtr()));
        assert(bool(m_hypothetical_head.StatePtr()->HasParent()));

        // Thinking of m_hypothetical_head.StatePtr() as the top of the state stack, we want to get the
        // (current_child_depth-1)th element from the top.
        BranchStatePtr_ child_branch_node_ptr = m_hypothetical_head.StatePtr();
        for (std::uint32_t i = 0; i < current_child_depth-2; ++i)
        {
            // This assert checks that the stack depth is sufficient.
            assert(child_branch_node_ptr->HasParent());
            child_branch_node_ptr = child_branch_node_ptr->Parent();
        }
        std::uint32_t state_index = child_branch_node_ptr->Data();

        assert(state_index < Npda_::ms_state_count_);
        Npda_::State_ const &state = Npda_::ms_state_table_[state_index];
        // If there's an associated rule, then use the precedence from that.
        if (state.m_associated_rule_index < Grammar_::ms_rule_count_)
        {
            Grammar_::Rule_ const &associated_rule = Grammar_::ms_rule_table_[state.m_associated_rule_index];
            assert(associated_rule.m_precedence_index < Grammar_::ms_precedence_count_);
            return PrecedenceIndexRange(associated_rule.m_precedence_index, associated_rule.m_precedence_index);
        }
        // Otherwise (e.g. a RETURN or ABORT state), return default precedence.
        else
            return PrecedenceIndexRange(Grammar_::ms_default_precedence_index_, Grammar_::ms_default_precedence_index_);
    }
    else if (m_spec.m_type == REDUCE)
    {
        std::uint32_t reduction_rule_index = m_spec.m_single_data;
        Grammar_::Rule_ const &reduction_rule = Grammar_::ms_rule_table_[reduction_rule_index];
        assert(reduction_rule.m_precedence_index < Grammar_::ms_precedence_count_);
        return PrecedenceIndexRange(reduction_rule.m_precedence_index, reduction_rule.m_precedence_index);
    }
    else if (m_spec.m_type == SHIFT)
    {
        PrecedenceIndexRange retval(std::numeric_limits<std::uint32_t>::max(), std::numeric_limits<std::uint32_t>::min());
        assert(!m_child_nodes.empty());
        // The range is the smallest range encompassing the range of each child node.
        for (ChildMap::const_iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
        {
            ParseTreeNodeSet const &child_node_set = child_map_it->second;
            for (ParseTreeNodeSet::const_iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
            {
                assert(*child_it != NULL);
                ParseTreeNode_ const &child = **child_it;
                PrecedenceIndexRange child_precedence_index_range(child.ComputePrecedenceIndexRange(current_child_depth+1));
                retval.first = std::min(retval.first, child_precedence_index_range.first);
                retval.second = std::max(retval.second, child_precedence_index_range.second);
            }
        }
        assert(retval.first <= retval.second);
        return retval;
    }
    else
    {
        // TODO: Probably need to do something to determine if this can't happen or prevent it.
        assert(false);
        return PrecedenceIndexRange(Grammar_::ms_default_precedence_index_, Grammar_::ms_default_precedence_index_);
    }
}

bool Parser::ParseTreeNode_::HasShiftReduceConflict (ParseTreeNode_ *&shift, ParseTreeNode_ *&reduce)
{
    ChildMap::iterator shift_children_it = m_child_nodes.find(Spec(SHIFT));
    ChildMap::iterator reduce_children_it = m_child_nodes.find(Spec(REDUCE));
    if (shift_children_it == m_child_nodes.end() || reduce_children_it == m_child_nodes.end())
        return false;

    ParseTreeNodeSet &shift_children = shift_children_it->second;
    ParseTreeNodeSet &reduce_children = reduce_children_it->second;
    assert(shift_children.size() == 1);
    assert(reduce_children.size() == 1);

    shift = *shift_children.begin();
    reduce = *reduce_children.begin();
    return true;
}

void Parser::ParseTreeNode_::AddChild (ParseTreeNode_ *child)
{
    assert(child != NULL);
    assert(child->m_parent_node == NULL);
    assert(child->m_spec.m_type != ROOT);

    m_child_nodes[child->m_spec].insert(child);
    child->m_parent_node = this;
    child->m_depth = m_depth + 1; // Always +1 relative to parent.

    // If this node is SHIFT and the child is HPS, then add the child's NPDA state to this node's
    // m_child_branch_vector.  This is the only situation in which m_child_branch_vector is added to.
    if (m_spec.m_type == SHIFT && child->m_spec.m_type == HPS)
    {
        assert(bool(child->m_hypothetical_head.StatePtr()));
        assert(std::none_of(m_child_branch_vector.begin(), m_child_branch_vector.end(), [child](Branch_ const &node_state){ return node_state.StatePtr() == child->m_hypothetical_head.StatePtr(); }) && "child branch node should not already be in the set");
        m_child_branch_vector.push_back(child->m_hypothetical_head);
    }
}

void Parser::ParseTreeNode_::RemoveChild (ParseTreeNode_ *child)
{
    assert(child != NULL);
    assert(child->m_parent_node == this);
    assert(HasChildrenHavingSpec(child->m_spec));
    assert(m_child_nodes[child->m_spec].find(child) != m_child_nodes[child->m_spec].end());
    m_child_nodes[child->m_spec].erase(child);
    if (m_child_nodes[child->m_spec].empty())
        m_child_nodes.erase(child->m_spec);
    child->m_parent_node = NULL;
    child->m_depth = 0; // Reset.

    // If there are no children and this isn't the root node, remove it from its parent.
    if (m_child_nodes.empty() && m_parent_node != NULL)
        RemoveFromParent();
}

void Parser::ParseTreeNode_::RemoveFromParent ()
{
    assert(m_parent_node != NULL);
    m_parent_node->RemoveChild(this);
}

void Parser::ParseTreeNode_::NullifyHPSNodeDescendantsInHPSQueue (HPSQueue_ &hps_queue) const
{
    if (m_spec.m_type == HPS)
    {
        // NOTE: This is a linear search, which is not as efficient as a different way of handling this.
        HPSQueue_::iterator it = std::find(hps_queue.begin(), hps_queue.end(), this);
        if (it != hps_queue.end())
            *it = NULL;
    }
    for (ChildMap::const_iterator child_map_it = m_child_nodes.begin(), child_map_it_end = m_child_nodes.end(); child_map_it != child_map_it_end; ++child_map_it)
    {
        ParseTreeNodeSet const &child_node_set = child_map_it->second;
        for (ParseTreeNodeSet::const_iterator child_it = child_node_set.begin(), child_it_end = child_node_set.end(); child_it != child_it_end; ++child_it)
        {
            assert(*child_it != NULL);
            ParseTreeNode_ const &child = **child_it;
            child.NullifyHPSNodeDescendantsInHPSQueue(hps_queue);
        }
    }
}

Parser::ParseTreeNode_ *Parser::ParseTreeNode_::CloneLeafNode () const
{
    ParseTreeNode_ *retval = new ParseTreeNode_(m_spec);
    CloneLeafNodeInto(*retval);
    return retval;
}

void Parser::ParseTreeNode_::CloneLeafNodeInto (Parser::ParseTreeNode_ &orphan_target) const
{
    assert(orphan_target.m_parent_node == NULL);
    assert(m_child_nodes.empty());
    orphan_target.m_spec                                    = m_spec;
    orphan_target.m_hypothetical_head                       = m_hypothetical_head;
    orphan_target.m_hypothetical_lookahead_token_id_queue   = m_hypothetical_lookahead_token_id_queue;
    orphan_target.m_realized_lookahead_cursor               = m_realized_lookahead_cursor;
}

void Parser::ParseTreeNode_::Print (std::ostream &out, Parser const *parser, std::string const &prefix, std::uint32_t indent_level, bool suppress_initial_prefix) const
{
    if (!suppress_initial_prefix)
    {
        out << prefix;
        for (std::uint32_t i = 0; i < indent_level; ++i)
            out << "    ";
    }
    out << AsString(m_spec.m_type) << ' ' << this << " (depth = " << m_depth << ')';
    if (m_spec.m_type == HPS)
    {
        out << (IsBlockedHPS() ? " (    blocked," : " (non-blocked,");
        out << " m_realized_lookahead_cursor = " << m_realized_lookahead_cursor << ')';
    }
    switch (m_spec.m_type)
    {
        case REDUCE:    out << " rule " << m_spec.m_single_data << "; " << Grammar_::ms_rule_table_[m_spec.m_single_data].m_description;  break;
        //case SHIFT:     out << " to (?) state " << m_spec.m_single_data << "; " << Npda_::ms_state_table_[m_spec.m_single_data].m_description; break;
        case SHIFT:     out << ' ' << Token(m_spec.m_single_data); break;
        case POP_STACK: out << ' ' << m_spec.m_single_data << " time(s)";                                                       break;
        default:                                                                                                                break;
    }
    if (bool(m_hypothetical_head.StatePtr()))
        out << ' ' << Npda_::ms_state_table_[m_hypothetical_head.StatePtr()->Data()].m_description << ' ';
    if (m_spec.m_type == HPS)
    {
        assert(bool(m_hypothetical_head.StatePtr()));
        assert(bool(m_hypothetical_head.TokenIdPtr()));

        out << "    (";
        m_hypothetical_head.StatePtr()->PrintRootToLeaf(out, IdentityTransform_<Npda_::StateIndex_>);
        out << "); ";

        m_hypothetical_head.TokenIdPtr()->PrintRootToLeaf(out, TokenName_);
        out << " . ";
        for (std::size_t i = 0; i < m_hypothetical_lookahead_token_id_queue.size(); ++i)
            out << ms_token_name_table_[m_hypothetical_lookahead_token_id_queue[i]] << ' ';
        out << ", ";
        if (parser != NULL)
            for (std::size_t i = m_realized_lookahead_cursor; i < parser->m_realized_state_->LookaheadQueue().size(); ++i)
                out << ms_token_name_table_[parser->m_realized_state_->LookaheadQueue()[i].m_id] << ' ';
        else
            out << "<realized-lookaheads-not-printed>";
    }
    out << '\n';

    // Print children recursively with higher indent level
    for (ChildMap::const_iterator it = m_child_nodes.begin(), it_end = m_child_nodes.end(); it != it_end; ++it)
    {
        ParseTreeNodeSet const &child_node_set = it->second;
        for (ParseTreeNodeSet::const_iterator set_it = child_node_set.begin(), set_it_end = child_node_set.end(); set_it != set_it_end; ++set_it)
            (*set_it)->Print(out, parser, prefix, indent_level+1);
    }
}

// ////////////////////////////////////////////////////////////////////////////
// End of Parser::ParseTreeNode_
// ////////////////////////////////////////////////////////////////////////////

Parser::Token const &Parser::Lookahead_ (TokenQueue_::size_type index) throw()
{
    while (index >= m_realized_state_->LookaheadQueue().size())
    {
        // This does not require updating the hps-es' m_realized_lookahead_cursor.
        m_realized_state_->PushBackLookahead(Scan_(), m_hypothetical_state_->m_hps_queue);

        TRISON_CPP_DEBUG_CODE_(DSF_SCANNER_ACTION, *DebugSpewStream() << "Parser: " << "Retrieved token " << m_realized_state_->LookaheadQueue().back() << " from scan actions; pushing token onto back of lookahead queue\n")
    }
    return m_realized_state_->LookaheadQueue()[index];
}

Parser::ParseTreeNode_ *Parser::TakeHypotheticalActionOnHPS_ (ParseTreeNode_ const &hps, ParseTreeNode_::Type action_type, std::uint32_t action_data)
{
    // TODO: replace individual arguments action_type, action_data with ParseTreeNode_::Spec and just modify that struct below where it needs it.
    assert(hps.m_spec.m_type == ParseTreeNode_::HPS && "Only a HPS type node can take an action");
    assert(hps.m_parent_node != NULL);

    ParseTreeNode_ *new_hps = NULL;

    switch (action_type)
    {
        case ParseTreeNode_::ROOT: {
            assert(false && "ParseTreeNode_::ROOT is an invalid action type.");
            break;
        }
        case ParseTreeNode_::RETURN: {
            new_hps = hps.CloneLeafNode();
            break;
        }
        case ParseTreeNode_::ABORT: {
            new_hps = hps.CloneLeafNode();
            break;
        }
        case ParseTreeNode_::REDUCE: {
            // Execute the appropriate rule on the top tokens in the stack
            std::uint32_t const &rule_index = action_data;
            Grammar_::Rule_ const &rule = Grammar_::ms_rule_table_[rule_index];

            // Avoid creating the new hps altogether if it won't be added due to a REDUCE/REDUCE conflict.
            ParseTreeNode_ *existing_reduce_action_node = NULL;
            ParseTreeNode_ *reduce_hps = NULL;
            ParseTreeNode_::Spec action_spec(action_type, action_data);
            if (hps.m_parent_node->HasChildrenHavingSpec(action_spec)) // Check for an existing REDUCE action
            {
                // This may or may not be a conflict.  Need to determine that.

                ParseTreeNode_::ParseTreeNodeSet &reduce_node_set = hps.m_parent_node->ChildrenHavingSpec(action_spec);
                assert(reduce_node_set.size() == 1);
                existing_reduce_action_node = *reduce_node_set.begin();
                assert(existing_reduce_action_node != NULL);
                assert(existing_reduce_action_node->m_spec.m_type == ParseTreeNode_::REDUCE);

                if (false)
                {
                    // TEMP
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "\n\nHIPPO existing_reduce_action_node child nodes:\n\n")
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, PrintParserStatus_(*DebugSpewStream()))
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "\n\n")
                }

                // If the hypothetical action is identical to the existing one, then there's no problem,
                // just add it as a child to the existing one.
                if (existing_reduce_action_node->m_spec.m_single_data == rule_index)
                {
                    new_hps = hps.CloneLeafNode();
                    reduce_hps = new_hps;
                }
                // Otherwise this is a REDUCE/REDUCE conflict
                else
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "Parser: " << "TakeHypotheticalActionOnHPS_ - REDUCE/REDUCE conflict encountered ... ")

                    // If the new REDUCE action beats the existing one in a conflict, just replace the existing one
                    // (replacement instead of creating a new one and deleting the old is an optimization which also
                    // avoids an annoying traversal through m_hypothetical_state_->m_hps_queue).
                    // NOTE: This depends on the fact that a REDUCE node has exactly one HPS child,
                    // which is what these three asserts check.  TODO: maybe make abstractions for these sorts of checks.
                    assert(existing_reduce_action_node->m_child_nodes.size() == 1);
                    assert(existing_reduce_action_node->m_child_nodes.begin()->second.size() == 1);
                    assert((*existing_reduce_action_node->m_child_nodes.begin()->second.begin())->m_spec.m_type == ParseTreeNode_::HPS);
                    if (Grammar_::CompareRuleByPrecedence_(action_data, existing_reduce_action_node->m_spec.m_single_data))
                    {
                        TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "resolving in favor of new hps because its REDUCE action has higher precedence.")

                        reduce_hps = *existing_reduce_action_node->m_child_nodes.begin()->second.begin();
                        assert(reduce_hps != NULL);

                        // Remove the nodes from the ParseTreeNode_ tree.
                        assert(existing_reduce_action_node != NULL);
                        existing_reduce_action_node->RemoveFromParent();
                        reduce_hps->RemoveFromParent();
                        // Modify the nodes.
                        existing_reduce_action_node->m_spec = action_spec; // Replace with the winning reduction rule Spec.
                        hps.CloneLeafNodeInto(*reduce_hps); // NOTE: This modifies the existing hps, so no update of m_hypothetical_state_->m_hps_queue is necessary.
                        // Re-add them to the ParseTreeNode_ tree.
                        existing_reduce_action_node->AddChild(reduce_hps);
                        hps.m_parent_node->AddChild(existing_reduce_action_node);
                    }
                    else
                    {
                        TRISON_CPP_DEBUG_CODE_(DSF_REDUCE_REDUCE_CONFLICT, *DebugSpewStream() << "resolving in favor of existing hps.")
                    }
                    assert(existing_reduce_action_node->m_child_nodes.begin()->second.size() == 1);
                }
            }
            else
            {
                new_hps = hps.CloneLeafNode();
                reduce_hps = new_hps;
            }

            if (reduce_hps != NULL)
            {
                // Pop those stack tokens.
                for (std::uint32_t i = 0; i < rule.m_token_count; ++i)
                {
                    assert(reduce_hps->m_hypothetical_head.HasParent());
                    reduce_hps->m_hypothetical_head = reduce_hps->m_hypothetical_head.Parent();
                }
                // Push the reduced nonterminal token data onto the front of the lookahead queue
                reduce_hps->m_hypothetical_lookahead_token_id_queue.push_front(rule.m_reduction_nonterminal_token_id);
            }

            break;
        }
        case ParseTreeNode_::SHIFT: {
            // Move the front of the lookahead queue to the top of the stack, assigning the appropriate state index.
            std::uint32_t const &state_index = action_data;
            // TODO: probably make "Shift" method for ParseTreeNode_ to do all this bookkeeping and parallel LookaheadTokenId tracking.
            new_hps = hps.CloneLeafNode();
            Token::Id lookahead_token_id = new_hps->LookaheadTokenId(*this);
            // Create a new Branch_ and link it to the parent node's.
            new_hps->m_hypothetical_head = Branch_(BranchState_::CreateWithParent(hps.m_hypothetical_head.StatePtr(), state_index), BranchTokenId_::CreateWithParent(hps.m_hypothetical_head.TokenIdPtr(), lookahead_token_id));
            assert(new_hps->m_hypothetical_head.HasParent());
            assert(new_hps->m_hypothetical_head.Parent() == hps.m_hypothetical_head);

            // Store the lookahead token id in action_data so it can printed.
            action_data = std::uint32_t(lookahead_token_id);
            if (new_hps->m_hypothetical_lookahead_token_id_queue.empty())
                ++new_hps->m_realized_lookahead_cursor;
            else
                new_hps->m_hypothetical_lookahead_token_id_queue.pop_front();
            break;
        }
        case ParseTreeNode_::INSERT_LOOKAHEAD_ERROR: {
            new_hps = hps.CloneLeafNode();
            new_hps->m_hypothetical_lookahead_token_id_queue.push_front(Terminal::ERROR_);
            break;
        }
        case ParseTreeNode_::DISCARD_LOOKAHEAD: {
            new_hps = hps.CloneLeafNode();
            if (new_hps->m_hypothetical_lookahead_token_id_queue.empty())
                ++new_hps->m_realized_lookahead_cursor;
            else
                new_hps->m_hypothetical_lookahead_token_id_queue.pop_front();
            break;
        }
        case ParseTreeNode_::POP_STACK: {
            // TODO: make separate action nodes for each pop, instead of using action data,
            // since for example two branches may agree on popping at least once, even if
            // one of them is killed later.
            std::uint32_t const &pop_count = action_data;
            assert(pop_count == 1 || pop_count == 2);
            assert(pop_count < hps.m_hypothetical_head.StatePtr()->BranchLength());
            // // Check if there are actually enough stack elements to pop successfully.
            // // If not, then don't create an HPS, and break early.
            // if (pop_count >= hps.m_hypothetical_head.StatePtr()->BranchLength())
            // {
            //     new_hps = NULL;
            //     break;
            // }

            new_hps = hps.CloneLeafNode();
            for (std::uint32_t i = 0; i < pop_count; ++i)
            {
                assert(new_hps->m_hypothetical_head.HasParent());
                new_hps->m_hypothetical_head = new_hps->m_hypothetical_head.Parent();
            }
            if (pop_count == 2)
                new_hps->m_hypothetical_lookahead_token_id_queue.push_front(Terminal::ERROR_);
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "creating HPS to be child of POP_STACK node... ")
            break;
        }
        case ParseTreeNode_::HPS: {
            assert(false && "ParseTreeNode_::HPS is an invalid action type.");
            break;
        }
        default: {
            assert(false && "invalid ParseTreeNode_::Type");
            break;
        }
    }

    if (new_hps != NULL)
    {
        assert(new_hps->m_parent_node == NULL);

        ParseTreeNode_ *action_node = NULL;

        // Ensure the action node exists, creating it if necessary.
        ParseTreeNode_::Spec action_spec(action_type, action_data);
        if (hps.m_parent_node->HasChildrenHavingSpec(action_spec))
        {
            ParseTreeNode_::ParseTreeNodeSet &children_of_action_type = hps.m_parent_node->ChildrenHavingSpec(action_spec);
            assert(children_of_action_type.size() == 1);
            action_node = *children_of_action_type.begin();
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "using existing action node of type " << ParseTreeNode_::AsString(action_spec.m_type) << "... ")

            // If the new hps already exists (can only happen as a child of POP_STACK), then don't add it.
            if (action_type == ParseTreeNode_::POP_STACK && action_node->HasChildrenHavingSpec(new_hps->m_spec))
            {
                ParseTreeNode_::ParseTreeNodeSet const &child_hps_set = action_node->ChildrenHavingSpec(new_hps->m_spec);
                if (child_hps_set.find(new_hps) != child_hps_set.end())
                {
                    TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "not adding duplicate HPS as child of POP_STACK node... ")
                    delete new_hps;
                    new_hps = NULL;
                }
            }
        }
        else
        {
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "creating new action node of type " << ParseTreeNode_::AsString(action_spec.m_type) << "... ")
            action_node = new ParseTreeNode_(action_spec);
            TRISON_CPP_DEBUG_CODE_(DSF_HPS_NODE_CREATION_DELETION, *DebugSpewStream() << "(action_node = " << action_node << ") ")
            hps.m_parent_node->AddChild(action_node);
        }

        if (new_hps != NULL)
            action_node->AddChild(new_hps);
    }

    return new_hps;
}

void Parser::CreateParseTreeFromRealizedState_ ()
{
    BranchVector_ const &reconstruct_branch_vector = m_realized_state_->BranchVectorStack().back();

    // Add HPS nodes for each branch in the top of the realized state stack.
    assert(!reconstruct_branch_vector.empty());
    TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << "        Reconstructing branches:\n")
    for (BranchVector_::const_iterator it = reconstruct_branch_vector.begin(), it_end = reconstruct_branch_vector.end(); it != it_end; ++it)
    {
        Branch_ const &reconstruct_branch = *it;
        TRISON_CPP_DEBUG_CODE_(DSF_PARSE_TREE_MESSAGE, *DebugSpewStream() << "Parser: " << "            " << reconstruct_branch.StatePtr() << '\n')

        ParseTreeNode_ *hps             = new ParseTreeNode_(ParseTreeNode_::Spec(ParseTreeNode_::HPS));
        hps->m_hypothetical_head        = reconstruct_branch;

        m_hypothetical_state_->m_root->AddChild(hps);
        m_hypothetical_state_->m_hps_queue.push_back(hps);
    }
}

void Parser::ClearStack_ ()
{
    if (m_realized_state_ != NULL)
    {
        // TODO: Could print the m_realized_state_ m_branch_vector_stack element being popped.
        while (!m_realized_state_->TokenStack().empty())
            ThrowAwayToken_(std::move(m_realized_state_->PopStack()));
    }

    delete m_hypothetical_state_;
    m_hypothetical_state_ = NULL;
}

void Parser::CleanUpAllInternals_ ()
{
    if (m_realized_state_ != NULL)
    {
        // TODO: Could print the m_realized_state_ m_branch_vector_stack element being popped.
        while (!m_realized_state_->TokenStack().empty())
            ThrowAwayToken_(std::move(m_realized_state_->PopStack()));

        while (!m_realized_state_->LookaheadQueue().empty())
            ThrowAwayToken_(std::move(m_realized_state_->PopFrontLookahead(m_hypothetical_state_->m_hps_queue)));

        // Note that this implicitly resets the error state (since that's tracked by m_realized_state_).
        delete m_realized_state_;
        m_realized_state_ = NULL;
    }

    delete m_hypothetical_state_;
    m_hypothetical_state_ = NULL;
}

// ////////////////////////////////////////////////////////////////////////////
// Parser::Grammar_
// ////////////////////////////////////////////////////////////////////////////

bool Parser::Grammar_::CompareRuleByPrecedence_ (std::uint32_t lhs_rule_index, std::uint32_t rhs_rule_index)
{
    if (ms_precedence_table_[ms_rule_table_[lhs_rule_index].m_precedence_index].m_level != ms_precedence_table_[ms_rule_table_[rhs_rule_index].m_precedence_index].m_level)
        return ms_precedence_table_[ms_rule_table_[lhs_rule_index].m_precedence_index].m_level > ms_precedence_table_[ms_rule_table_[rhs_rule_index].m_precedence_index].m_level;
    else
        return lhs_rule_index < rhs_rule_index;
}

// These values are prescribed within trison and can't be changed.
char const *const Parser::Grammar_::ms_associativity_string_table_[] =
{
    "%left",
    "%nonassoc",
    "%right",
};

std::size_t const Parser::Grammar_::ms_associativity_count_ = sizeof(Parser::Grammar_::ms_associativity_string_table_) / sizeof(*Parser::Grammar_::ms_associativity_string_table_);

Parser::Grammar_::Precedence_ const Parser::Grammar_::ms_precedence_table_[] =
{
    { 0, Parser::Grammar_::Associativity(0), "DEFAULT_" }
};

std::size_t const Parser::Grammar_::ms_precedence_count_ = sizeof(Parser::Grammar_::ms_precedence_table_) / sizeof(*Parser::Grammar_::ms_precedence_table_);

std::size_t const Parser::Grammar_::ms_default_precedence_index_ = 0;

Parser::Grammar_::Rule_ const Parser::Grammar_::ms_rule_table_[] =
{
    { Parser::Nonterminal::root, 2, false, 0, "root <- expression_list END_" },
    { Parser::Nonterminal::expression, 1, false, 0, "expression <- LEAF" },
    { Parser::Nonterminal::expression, 3, false, 0, "expression <- '(' expression_list ')'" },
    { Parser::Nonterminal::expression_list, 2, false, 0, "expression_list <- expression_list expression" },
    { Parser::Nonterminal::expression_list, 0, false, 0, "expression_list <-" }
};
std::size_t const Parser::Grammar_::ms_rule_count_ = sizeof(Parser::Grammar_::ms_rule_table_) / sizeof(*Parser::Grammar_::ms_rule_table_);

// ////////////////////////////////////////////////////////////////////////////
// Parser::Npda_
// ////////////////////////////////////////////////////////////////////////////

Parser::Npda_::StateIndexVector_ const &Parser::Npda_::EpsilonClosureOfState_ (StateIndex_ state_index)
{
    // Memoize this function, because it will be called so many times and is somewhat intensive.
    typedef std::map<StateIndex_,StateIndexVector_> LookupTable;
    static LookupTable s_lookup_table;

    LookupTable::iterator find_it = s_lookup_table.find(state_index);
    if (find_it != s_lookup_table.end())
        return find_it->second;

    // Compute the epsilon closure as a set
    StateIndexSet_ epsilon_closure_set;
    ComputeEpsilonClosureOfState_(state_index, epsilon_closure_set);

    // Copy the states in the set into the memoized vector.
//    std::cerr << "EpsilonClosureOfState_(" << state_index << "):"; // HIPPO
    StateIndexVector_ &epsilon_closure = s_lookup_table[state_index];
    epsilon_closure.reserve(epsilon_closure_set.size());
    for (StateIndexSet_::const_iterator it = epsilon_closure_set.begin(), it_end = epsilon_closure_set.end(); it != it_end; ++it)
    {
//        std::cerr << ' ' << *it; // HIPPO
        epsilon_closure.push_back(*it);
    }
//    std::cerr << ";\n"; // HIPPO
    // Return the memoized value.
    return epsilon_closure;
}

void Parser::Npda_::ComputeEpsilonClosureOfState_ (StateIndex_ state_index, StateIndexSet_ &epsilon_closure)
{
    // NOTE: The working definition of epsilon closure in this implementation used to only include
    // states that had non-epsilon transitions, but has been changed to include all epsilon-reachable
    // states, including those having no non-epsilon transitions.

    // This implementation allows epsilon cycles.

    // If this state has already been visited, there's no reason to continue.
    if (epsilon_closure.find(state_index) != epsilon_closure.end())
        return;
    // Otherwise, mark it as visited.  This also prevents infinite recursion.
    else
        epsilon_closure.insert(state_index);

    // This set collects the epsilon closure with no duplicates
    State_ const &state = ms_state_table_[state_index];
    for (Transition_ const *transition = state.m_transition_table, *transition_end = state.m_transition_table+state.m_transition_count;
         transition != transition_end;
         ++transition)
    {
        if (transition->m_type == Transition_::EPSILON)
            ComputeEpsilonClosureOfState_(transition->m_data_index, epsilon_closure);
    }
}

Parser::Npda_::TransitionVector_ const &Parser::Npda_::NonEpsilonTransitionsOfState_ (StateIndex_ state_index, std::uint32_t sorted_type_index)
{
    assert(Transition_::Order::MIN_SORTED_TYPE_INDEX <= sorted_type_index && sorted_type_index <= Transition_::Order::MAX_SORTED_TYPE_INDEX);

    // Memoize this function, because it will be called so many times and is somewhat intensive.
    typedef std::pair<StateIndex_,std::uint32_t> KeyType;
    typedef std::map<KeyType,TransitionVector_> LookupTable;
    static LookupTable s_lookup_table;

    KeyType key(state_index, sorted_type_index);
    LookupTable::iterator it = s_lookup_table.find(key);
    if (it != s_lookup_table.end())
        return it->second;

    // TODO: probably don't need to memoize epsilon closures because non-epsilon transitions is memoized.
    TransitionSet_ non_epsilon_transition_set;
    StateIndexVector_ const &epsilon_closure = EpsilonClosureOfState_(state_index);
    for (StateIndexVector_::const_iterator it = epsilon_closure.begin(), it_end = epsilon_closure.end(); it != it_end; ++it)
    {
        State_ const &state = ms_state_table_[*it];
        for (Transition_ const *transition = state.m_transition_table, *transition_end = state.m_transition_table+state.m_transition_count; transition != transition_end; ++transition)
        {
            std::uint32_t transition_sorted_type_index = Transition_::Order::SortedTypeIndex(*transition);
            if (transition->m_type != Transition_::EPSILON && transition_sorted_type_index == sorted_type_index)
                non_epsilon_transition_set.insert(*transition);
        }
    }

    TransitionVector_ &non_epsilon_transitions = s_lookup_table[key];
    non_epsilon_transitions.reserve(non_epsilon_transition_set.size());
    for (TransitionSet_::const_iterator it = non_epsilon_transition_set.begin(), it_end = non_epsilon_transition_set.end(); it != it_end; ++it)
        non_epsilon_transitions.push_back(*it);
    return non_epsilon_transitions;
}

Parser::Npda_::State_ const Parser::Npda_::ms_state_table_[] =
{
    { 1, ms_transition_table_+0, 5, "FALLBACK" },
    { 2, ms_transition_table_+1, 5, "START root" },
    { 1, ms_transition_table_+3, 5, "RETURN root" },
    { 1, ms_transition_table_+4, 5, "head of: root" },
    { 4, ms_transition_table_+5, 0, "rule 0: root <- . expression_list END_" },
    { 3, ms_transition_table_+9, 0, "rule 0: root <- expression_list . END_" },
    { 2, ms_transition_table_+12, 5, "START expression_list" },
    { 1, ms_transition_table_+14, 5, "RETURN expression_list" },
    { 2, ms_transition_table_+15, 5, "head of: expression_list" },
    { 3, ms_transition_table_+17, 3, "rule 3: expression_list <- . expression_list expression" },
    { 4, ms_transition_table_+20, 3, "rule 3: expression_list <- expression_list . expression" },
    { 1, ms_transition_table_+24, 3, "rule 3: expression_list <- expression_list expression ." },
    { 2, ms_transition_table_+25, 5, "START expression" },
    { 1, ms_transition_table_+27, 5, "RETURN expression" },
    { 2, ms_transition_table_+28, 5, "head of: expression" },
    { 3, ms_transition_table_+30, 1, "rule 1: expression <- . LEAF" },
    { 1, ms_transition_table_+33, 1, "rule 1: expression <- LEAF ." },
    { 3, ms_transition_table_+34, 2, "rule 2: expression <- . '(' expression_list ')'" },
    { 4, ms_transition_table_+37, 2, "rule 2: expression <- '(' . expression_list ')'" },
    { 3, ms_transition_table_+41, 2, "rule 2: expression <- '(' expression_list . ')'" },
    { 1, ms_transition_table_+44, 2, "rule 2: expression <- '(' expression_list ')' ." },
    { 1, ms_transition_table_+45, 4, "rule 4: expression_list <- ." },
    { 1, ms_transition_table_+46, 0, "rule 0: root <- expression_list END_ ." }
};
std::size_t const Parser::Npda_::ms_state_count_ = sizeof(Parser::Npda_::ms_state_table_) / sizeof(*Parser::Npda_::ms_state_table_);

Parser::Npda_::Transition_ const Parser::Npda_::ms_transition_table_[] =
{
    { Parser::Npda_::Transition_::ABORT, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::SHIFT, 260, std::uint32_t(2) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(3) },
    { Parser::Npda_::Transition_::RETURN, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(4) },
    { Parser::Npda_::Transition_::SHIFT, 262, std::uint32_t(5) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(8) },
    { Parser::Npda_::Transition_::SHIFT, 256, std::uint32_t(22) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::SHIFT, 262, std::uint32_t(7) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(8) },
    { Parser::Npda_::Transition_::RETURN, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(9) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(21) },
    { Parser::Npda_::Transition_::SHIFT, 262, std::uint32_t(10) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::SHIFT, 261, std::uint32_t(11) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(14) },
    { Parser::Npda_::Transition_::REDUCE, 0, std::uint32_t(3) },
    { Parser::Npda_::Transition_::SHIFT, 261, std::uint32_t(13) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(14) },
    { Parser::Npda_::Transition_::RETURN, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(15) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(17) },
    { Parser::Npda_::Transition_::SHIFT, 259, std::uint32_t(16) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::REDUCE, 0, std::uint32_t(1) },
    { Parser::Npda_::Transition_::SHIFT, 40, std::uint32_t(18) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::SHIFT, 262, std::uint32_t(19) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::EPSILON, 0, std::uint32_t(8) },
    { Parser::Npda_::Transition_::SHIFT, 41, std::uint32_t(20) },
    { Parser::Npda_::Transition_::INSERT_LOOKAHEAD_ERROR, 0, std::uint32_t(-1) },
    { Parser::Npda_::Transition_::POP_STACK, 257, std::uint32_t(1) },
    { Parser::Npda_::Transition_::REDUCE, 0, std::uint32_t(2) },
    { Parser::Npda_::Transition_::REDUCE, 0, std::uint32_t(4) },
    { Parser::Npda_::Transition_::REDUCE, 0, std::uint32_t(0) }
};
std::size_t const Parser::Npda_::ms_transition_count_ = sizeof(Parser::Npda_::ms_transition_table_) / sizeof(*Parser::Npda_::ms_transition_table_);

// ///////////////////////////////////////////////////////////////////////
// end of internal trison-generated parser guts
// ///////////////////////////////////////////////////////////////////////


#line 62 "../using_unique_ptr_parser.trison"

void Parser::set_istream_iterator (std::istream_iterator<char> it)
{
    // This will delete any existing pointer owned by m_scanner.
    // Note that in C++14, we would be able to use std::make_unique.
    m_scanner = std::unique_ptr<Scanner>(new Scanner());
    m_scanner->IstreamIterator(it);
    ResetForNewInput();
}

#line 2729 "../using_unique_ptr_parser.cpp"
